# 后端面试

## 后端面试

## 基础 

### ★★★ 进程与线程的本质区别、以及各自的使用场景。

1. 进程

进程是资源（CPU、内存等）分配的基本单位，它是程序执行时的一个实例。

程序运行时系统就会创建一个进程，并为它分配资源，然后把该进程放入进程就绪队列

进程调度器选中它的时候就会为它分配CPU时间，程序开始真正运行。

1.1 进程的状态和切换

* 就绪状态：进程已获得除处理机以外的所需资源，等待分配处理机资源
* 运行状态：占用处理机资源运行，处于此状态的进程数小于等于CPU数
* 阻塞状态： 进程等待某种条件，在条件满足之前无法执行

操作系统为了控制进程的执行，必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行，这种行为被称为进程切换，任务切换或上下文切换。  


![](../.gitbook/assets/image%20%28102%29.png)

![](../.gitbook/assets/image%20%28103%29.png)

2. 什么是线程

线程是程序执行时的最小单位，它是进程的一个执行流，是CPU调度和分派的基本单位。

一个进程可以由很多个线程组成，线程间共享进程的所有资源，每个线程有自己的堆栈和局部变量。

线程由CPU独立调度执行，在多CPU环境下就允许多个线程同时运行。同样多线程也可以实现并发操作，每个请求分配一个线程来处理。

3. 进行和线程之间的区别

1. 调度 ：在引入线程的操作系统中，线程是调度和分配的基本单位 ，进程是资源拥有的基本单位 。把传统进程的两个属性分开，线程便能轻装运行，从而可 显著地提高系统的并发程度 。在同一进程中，线程的切换不会引起进程的切换；在由一个进程中的线程切换到另一个进程中的线程时，才会引起进程的切换。
2. 并发性 ：在引入线程的操作系统中，不仅进程之间可以并发执行，而且在一个进程中的多个线程之间亦可并发执行，因而使操作系统具有更好的并发性，从而能 更有效地使用系统资源和提高系统吞吐量。
3. 拥有资源 ：不论是传统的操作系统，还是设有线程的操作系统，进程都是拥有资源的一个独立单位，它可以拥有自己的资源。一般地说，线程自己不拥有系统资源（只有一些必不可少的资源，但它可以访问其隶属进程的资源。
4. 系统开销：由于在创建或撤消进程时，系统都要为之分配或回收资源，因此，操作系统所付出的开销将显著地大于在创建或撤消线程时的开销。进程切换的开销也远大于线程切换的开销。
5. 通信：进程间通信IPC，线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性，因此共享简单。但是线程的数据同步要比进程略复杂。

4. 进行和线程之间的相同点

进程和线程都有ID/寄存器组、状态和优先权、信息块，创建后都可更改自己的属性，都可与父进程共享资源、都不能直接访问其他无关进程或线程的资源

5. 进程和线程的使用场景

有了以上进程和线程的异同点，不难得出结论：

1. 需要频繁创建销毁的优先使用线程；因为对进程来说创建和销毁一个进程代价是很大的。
2. 线程的切换速度快，所以在需要大量计算，切换频繁时用线程，还有耗时的操作使用线程可提高应用程序的响应
3. 因为对CPU系统的效率使用上线程更占优，所以可能要发展到多机分布的用进程，多核分布用线程；
4. 并行操作时使用线程，如C/S架构的服务器端并发线程响应用户的请求；
5. 需要更稳定安全时，适合选择进程；需要速度时，选择线程更好。

### ★☆☆ 进程状态。 

* 就绪状态：进程已获得除处理机以外的所需资源，等待分配处理机资源
* 运行状态：占用处理机资源运行，处于此状态的进程数小于等于CPU数
* 阻塞状态： 进程等待某种条件，在条件满足之前无法执行

操作系统为了控制进程的执行，必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行，这种行为被称为进程切换，任务切换或上下文切换。

### ★★★ 进程调度算法的特点以及使用场景。 

1、时间片轮转调度算法（RR）：给每个进程固定的执行时间，根据进程到达的先后顺序让进程在单位时间片内执行，执行完成后便调度下一个进程执行，时间片轮转调度不考虑进程等待时间和执行时间，属于抢占式调度。优点是兼顾长短作业；缺点是平均等待时间较长，上下文切换较费时。适用于分时系统。

2、先来先服务调度算法（FCFS）：根据进程到达的先后顺序执行进程，不考虑等待时间和执行时间，会产生饥饿现象。属于非抢占式调度，优点是公平，实现简单；缺点是不利于短作业。

3、优先级调度算法（HPF）：在进程等待队列中选择优先级最高的来执行。常被用于批处理系统中，还可用于实时系统中。

4、多级反馈队列调度算法：将时间片轮转与优先级调度相结合，把进程按优先级分成不同的队列，先按优先级调度，优先级相同的，按时间片轮转。优点是兼顾长短作业，有较好的响应时间，可行性强，适用于各种作业环境。

5、高响应比优先调度算法：根据“响应比=（进程执行时间+进程等待时间）/ 进程执行时间”这个公式得到的响应比来进行调度。高响应比优先算法在等待时间相同的情况下，作业执行的时间越短，响应比越高，满足段任务优先，同时响应比会随着等待时间增加而变大，优先级会提高，能够避免饥饿现象。优点是兼顾长短作业，缺点是计算响应比开销大，适用于批处理系统。

### ★☆☆ 线程实现的方式。 

线程的3种实现方式

在引入线程的操作系统中，进程是资源分配的基本单位，线程是独立调度的基本单位。在同一进程中，线程的切换不会引起进程切换。在不同进程中进行线程切换,如从一个进程内的线程切换到另一个进程中的线程时，会引起进程切换。

线程分为两种：

| 名称 | 描述 |
| :--- | :--- |
| 用户级线程\(User-Level Thread, ULT\) | 由应用程序所支持的线程实现, 对内核不可见 |
| 内核级线程\(Kernel-Level Thread, KLT\) | 内核级线程又称为内核支持的线程 |

组合线程\(Hybrid Multithreading\)是一种别的实现方式而不是线程的种类。

### ★★☆ 协程的作用。 

1.协程的含义和实现

协程是单进程单线程的超越函数的调度机制，它通过一定的调度手段进行调度。

（Python使用generator机制，greenlet使用汇编控制对程序指向来实现）。

2.协程有什么作用

计算机分为IO bound 和CPU bound两种类型的task。在这两种情况中，协程都没有什么作用。

为什么？

在CPU bound task中，cpu被用来执行任务去了。这类task，即使一个一个方法的执行，跟协程的效率还要高出一点点，使用协程没有意义。IO bound task中，CPU已经陷入系统调用之中，用户空间的调度无论如何也是没有CPU的，这样情况下，协程只能死死的。在这样情况下，祈求高效率，怎么可能。

协程只有在非常有限制的情况下，才有一些用处，在单进程单线程任务中的交互青霞，才有它的用武之地。

3.协程不是未来（反驳赖勇浩）。协程是很早之前就有的。很早之前，windows就有纤程的概念，Linux不太确定。但是它一直作为小众的API而存在。

4.gevnet+flask是一个很流行的用法，但是gevent真正有用的是libev，它是使用epoll\(linux\), kqueue\(bsd\),IOCP\(windows\)实现network IO，并在轮询处理signal，signal，callback的lib。

### ★★☆ 常见进程同步问题。 

 生产者-消费者（三个信号量）

empty：缓冲区 空闲 资源数，full：缓冲区 已满 资源数 ： 保证不会空时消费，满时生产（保证顺序、同步） mutex 代表互斥锁 ： 保证同一时间只有一个线程可以访问共享资源（互斥访问）

 读者-写者问题 （可以多个进程同时读，但是写时就只能有一个写）

wmutex： 互斥的写 （写时不能读，只能一个写） rmutex： 互斥的使用readcount（对readcount加锁） readcount： 统计读进程数目，及读者数量（临界资源，多个读进程共享）

 哲学家进餐问题 ： 只允许同时拿起左右两边的筷子

mutex: 互斥量，对拿起左右两只筷子加锁（只有一个进程能访问）

### ★★★ 进程通信方法的特点以及使用场景。

一、共享内存通信

共享内存是指多个进程共享一块内存，是专门用来解决不同进程之间的通信问题的，由于是直接对内存进行数据传输操作，所以是速度最快的IPC（inter-process communication）方式，因为是共享内存，所以需要配合信号量机制实现同步。

二、管道通信

无名管道\( pipe \)：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。

当一个管道建立时，它会创建两个文件描述符：`fd[0]`为读而打开，`fd[1]`为写而打开。如下图：

![](https://img-blog.csdnimg.cn/20190731095842458.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTA3NzIz,size_16,color_FFFFFF,t_70)

高级管道\(popen\)：将另一个程序当做一个新的进程在当前程序进程中启动，则它算是当前程序的子进程，这种方式我们成为高级管道方式。

有名管道 \(named pipe\) ： 有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。

三、消息队列通信

消息队列\( message queue \) ： 消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。

四、套接字通信

套接字\( socket \) ： 套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同机器间的进程通信。

### ★★★ 死锁必要条件、解决死锁策略，能写出和分析死锁的代码，能说明在数据库管理系统或者 Java 中如何解决死锁。 

必要条件：

互斥条件（Mutual exclusion）：资源不能被共享，只能由一个进程使用。 

请求与保持条件（Hold and wait）：已经得到资源的进程可以再次申请新的资源。 

不可剥夺剥夺条件（No pre-emption）：已经分配的资源不能从相应的进程中被强制地剥夺。 

环路等待条件（Circular wait）：系统中若干进程组成环路，该环路中每个进程都在等待相邻进程正占用的资源。

解决策略：

1\) 死锁预防：预先静态分配法：破坏了“不可剥夺条件”，资源有序分配法：破坏了“环路条件”

2）死锁避免：设法破坏4个必要条件之一，严格防止死锁的发生。银行家算法：若发现分配资源后进入不安全状态，则不予分配；若扔处于安全状态，则实施分配。

3）死锁检测：允许死锁产生，定时地运行一个死锁检测程序，判断系统是否发生死锁。

4）死锁解除：资源剥夺法，撤销进程法

### ★★★ 虚拟内存的作用，分页系统实现虚拟内存原理。 

虚拟内存是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。 

虚拟地址被分成虚拟页号（高地址）和偏移量（低地址）两部分。不同的划分对应了不同的页面大小。

 虚拟页号可作为页表的索引，以找到该虚拟页面对应的页表项。由页表项可以找到对应的页框。然后把页框号拼接到偏移量的高位端，以替换调虚拟页号，形成送往内存的物理地址。 

### ★★★ 页面置换算法的原理，特别是 LRU 的实现原理，最好能手写，再说明它在 Redis 等作为缓存置换算法。 

LRU（Least recently used，最近最少使用）

LRU算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。

基本思路

1. 新数据插入到列表头部；
2. 每当缓存命中（即缓存数据被访问），则将数据移到列表头部；
3. 当列表满的时候，将列表尾部的数据丢弃。

```python
class DLinkedNode:
    def __init__(self, key=0, value=0):
        self.key = key
        self.value = value
        self.prev = None
        self.next = None


class LRUCache:

    def __init__(self, capacity: int):
        self.cache = dict()
        # 使用伪头部和伪尾部节点    
        self.head = DLinkedNode()
        self.tail = DLinkedNode()
        self.head.next = self.tail
        self.tail.prev = self.head
        self.capacity = capacity
        self.size = 0

    def get(self, key: int) -> int:
        if key not in self.cache:
            return -1
        # 如果 key 存在，先通过哈希表定位，再移到头部
        node = self.cache[key]
        self.moveToHead(node)
        return node.value

    def put(self, key: int, value: int) -> None:
        if key not in self.cache:
            # 如果 key 不存在，创建一个新的节点
            node = DLinkedNode(key, value)
            # 添加进哈希表
            self.cache[key] = node
            # 添加至双向链表的头部
            self.addToHead(node)
            self.size += 1
            if self.size > self.capacity:
                # 如果超出容量，删除双向链表的尾部节点
                removed = self.removeTail()
                # 删除哈希表中对应的项
                self.cache.pop(removed.key)
                self.size -= 1
        else:
            # 如果 key 存在，先通过哈希表定位，再修改 value，并移到头部
            node = self.cache[key]
            node.value = value
            self.moveToHead(node)
    
    def addToHead(self, node):
        node.prev = self.head
        node.next = self.head.next
        self.head.next.prev = node
        self.head.next = node
    
    def removeNode(self, node):
        node.prev.next = node.next
        node.next.prev = node.prev

    def moveToHead(self, node):
        self.removeNode(node)
        self.addToHead(node)

    def removeTail(self):
        node = self.tail.prev
        self.removeNode(node)
        return node
```

### ★★★ 比较分页与分段的区别。 

1 页是信息的物理单位，分页是为了实现离散分配方式，以消减内存的外零头，提高内存的利用率。分页仅仅是由于系统管理的需要而不是用户的需要

   段是信息的逻辑单位，分段的目的是为了能更好地满足用户的需要

2 页的大小固定，由系统把逻辑地址划分为页号和页内地址两部分，段的长度却不固定，决定于用户所编写的程序

3 分页的作业地址空间是一维的，即单一的线性地址空间。 分段的作业地址空间是二维的 在标识一个地址时，即需给出段名，又需给出段内地址

### ★★★ 分析静态链接的不足，以及动态链接的特点。

1 静态链接库的优点 

 \(1\) 代码装载速度快，执行速度略比动态链接库快； 

 \(2\) 只需保证在开发者的计算机中有正确的.LIB文件，在以二进制形式发布程序时不需考虑在用户的计算机上.LIB文件是否存在及版本问题，可避免DLL地狱等问题。 

2 动态链接库的优点 

 \(1\) 更加节省内存并减少页面交换；

 \(2\) DLL文件与EXE文件独立，只要输出接口不变（即名称、参数、返回值类型和调用约定不变），更换DLL文件不会对EXE文件造成任何影响，因而极大地提高了可维护性和可扩展性；

 \(3\) 不同编程语言编写的程序只要按照函数调用约定就可以调用同一个DLL函数；

 \(4\)适用于大规模的软件开发，使开发过程独立、耦合度小，便于不同开发者和开发组织之间进行开发和测试

3 不足之处

 \(1\) 使用静态链接生成的可执行文件体积较大，包含相同的公共代码，造成浪费；

 \(2\) 使用动态链接库的应用程序不是自完备的，它依赖的DLL模块也要存在，如果使用载入时动态链接，程序启动时发现DLL不存在，系统将终止程序并给出错误信息。而使用运行时动态链接，系统不会终止，但由于DLL中的导出函数不可用，程序会加载失败；速度比静态链接慢。当某个模块更新后，如果新模块与旧的模块不兼容，那么那些需要该模块才能运行的软件，统统撕掉。这在早期Windows中很常见。

## Linux

### ★★☆ 文件系统的原理，特别是 inode 和 block。数据恢复原理。 

磁盘要分区，然后格式化，创建文件系统。

在每个linux存储设备或存储设备的分区被格式化为ext4文件系统后，一般都有两部分：

第一部分是INode。inode包含的属性信息包括文件大小、属性、归属的用户组，读写权限、文件类型、修改时间，还包含指向文件实体的指针的功能。（文件名不属于文件的属性，inode不包含文件名）

第二部分是block。Block用来存储实际数据的，例如照片，视频等普通文件数据。

数据恢复原理：删除的数据并没有被删除，只是标记为此处空闲，可以写入数据。

### ★★★ 硬链接与软链接的区别。

![](../.gitbook/assets/image%20%28100%29.png)

###  ★★☆ 能够使用常用的命令，比如 cat 文件内容查看、find 搜索文件，以及 cut、sort 等管线命令。了解 grep 和 awk 的作用。 

cat 文件名 查看文件内容内容 -n 列出行号

find 查找位置 -name 文件名

grep 主要用于搜索某些字符串 sed，awk 用于处理文本

### ★★★ 僵尸进程与孤儿进程的区别，从 SIGCHLD 分析产生僵尸进程的原因。

 **僵尸进程：**一个子进程在其父进程还没有来得及调用wait\(\)或waitpid\(\)来获取子进程的信号状态的情况下退出，那么这个子进程就是僵尸进程。子进程结束后会向父进程发出SIGCHLD信号。  
  
**孤儿进程：**一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程\(进程号为1\)所收养，并由init进程对它们完成状态收集工作。  




## 网络基础

### ★★★ 各层协议的作用，以及 TCP/IP 协议的特点。 

![](../.gitbook/assets/image%20%2899%29.png)

### ★★☆ 以太网的特点，以及帧结构。 

### ★★☆ 集线器、交换机、路由器的作用，以及所属的网络层。 

### ★★☆ IP 数据数据报常见字段的作用。 

### ★☆☆ ARP 协议的作用，以及维护 ARP 缓存的过程。 

### ★★☆ ICMP 报文种类以及作用；和 IP 数据报的关系；Ping 和 Traceroute 的具体原理。 

### ★★★ UDP 与 TCP 比较，分析上层协议应该使用 UDP 还是 TCP。 

1）TCP 是面向连接的传输。UDP 是无连接的传输

2）TCP 有流量控制、拥塞控制，检验数据数据按序到达，而 UDP 则相反。

3）TCP 的路由选择只发生在建立连接的时候，而 UDP 的每个报文都要进行路由选择

4）TCP 是可靠性传输，他的可靠性是由超时重发机制实现的，而 UDP则是不可靠传输

5）UDP 因为少了很多控制信息，所以传输速度比 TCP 速度快

6）TCP 适合用于传输大量数据，UDP 适合用于传输小量数据  
  
数据丢失，某些应用（例如audio）可以容忍某种程度上的数据丢失；而其他应用 （例如文件传输、telnet）要求100%可靠的数据传输。

实时性，某些应用（例如IP电话、交互式游戏等）要求较低的时延。

带宽，某些应用（例如多媒体）对最低带宽有要求；而其他应用（“弹性应用”）则可灵活应用所能得到的带宽。

### ★★★ 理解三次握手以及四次挥手具体过程，三次握手的原因、四次挥手原因、TIME\_WAIT 的作用。 

**三次握手**

第一次握手：客户端给服务端发一个 SYN 报文，并指明客户端的初始化序列号a。

第二次握手：服务器收到客户端的 SYN 报文之后，会以自己的 SYN 报文作为应答，并且也是指定了自己的初始化序列号 b。同时会把客户端的 a +1 作为ACK 的值

第三次握手：客户端收到 SYN 报文之后，会发送一个 ACK 报文，当然，也是一样把服务器的 b + 1 作为 ACK 的值，表示已经收到了服务端的 SYN 报文

在socket编程中，客户端执行connect\(\)时，将触发三次握手。

 **为什么需要三次握手，两次不行吗？**

如客户端发出连接请求，但因连接请求报文丢失而未收到确认，于是客户端再重传一次连接请求。后来收到了确认，建立了连接。数据传输完毕后，就释放了连接，客户端共发出了两个连接请求报文段，其中第一个丢失，第二个到达了服务端，但是第一个丢失的报文段只是在某些网络结点长时间滞留了，延误到连接释放以后的某个时间才到达服务端，此时服务端误认为客户端又发出一次新的连接请求，于是就向客户端发出确认报文段，同意建立连接，不采用三次握手，只要服务端发出确认，就建立新的连接了，此时客户端忽略服务端发来的确认，也不发送数据，则服务端一致等待客户端发送数据，浪费资源。

**四次挥手**

_注意: 中断连接端可以是客户端，也可以是服务器端. 下面仅以客户端断开连接举例, 反之亦然._

1. 客户端发送一个数据分段, 其中的 FIN 标记设置为1. 客户端进入 FIN-WAIT 状态. 该状态下客户端只接收数据, 不再发送数据.
2. 服务器接收到带有 FIN = 1 的数据分段, 发送带有 ACK = 1 的剩余数据分段, 确认收到客户端发来的 FIN 信息.
3. 服务器等到所有数据传输结束, 向客户端发送一个带有 FIN = 1 的数据分段, 并进入 CLOSE-WAIT 状态, 等待客户端发来带有 ACK = 1 的确认报文.
4. 客户端收到服务器发来带有 FIN = 1 的报文, 返回 ACK = 1 的报文确认, 为了防止服务器端未收到需要重发, 进入 TIME-WAIT 状态. 服务器接收到报文后关闭连接. 客户端等待 2MSL 后未收到回复, 则认为服务器成功关闭, 客户端关闭连接.

 **挥手为什么需要四次？**

因为当服务端收到客户端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当服务端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉客户端，“你发的FIN报文我收到了”。只有等到我服务端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四次挥手。

**TIME\_WAIT 的作用**

* 保证客户端发送的最后一个ACK报文段能够到达服务端。

这个ACK报文段有可能丢失，使得处于LAST-ACK状态的B收不到对已发送的FIN+ACK报文段的确认，服务端超时重传FIN+ACK报文段，而客户端能在2MSL时间内收到这个重传的FIN+ACK报文段，接着客户端重传一次确认，重新启动2MSL计时器，最后客户端和服务端都进入到CLOSED状态，若客户端在TIME-WAIT状态不等待一段时间，而是发送完ACK报文段后立即释放连接，则无法收到服务端重传的FIN+ACK报文段，所以不会再发送一次确认报文段，则服务端无法正常进入到CLOSED状态。

* 防止“已失效的连接请求报文段”出现在本连接中。

客户端在发送完最后一个ACK报文段后，再经过2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失，使下一个新的连接中不会出现这种旧的连接请求报文段。  


### ★★★ 可靠传输原理，并设计可靠 UDP 协议。 

### ★★☆ TCP 拥塞控制的作用，理解具体原理。 

### ★★☆ DNS 的端口号；TCP 还是 UDP；作为缓存、负载均衡。

## HTTP

### ★★★ GET 与 POST 比较：作用、参数、安全性、幂等性、可缓存。 

GET

1.GET是通过URL提交数据，因此GET可提交的数据量就跟URL所能达到的最大长度有直接关系。

2.实际上HTTP协议对URL长度是没有限制的；限制URL长度大多数是浏览器或者服务器的配置参数

POST

1.同样的，HTTP协议没有对POST进行任何限制，一般是受服务器配置限制或者内存大小。

2.PHP下可以修改php.conf的postmaxsize来设置POST的大小。

**请求header的content-length问题**

如果有人恶意伪造content-length很大的包头，但实际上发送content-length很小的请求，这样服务器会一直干等，直到超时。当然服务器是可以通过设置来避免该问题的

**GET和POST的安全性**

1.GET是通过URL方式请求，可以直接看到，明文传输。

2.POST是通过请求header请求，可以开发者工具或者抓包可以看到，同样也是明文的。 3.GET请求会保存在浏览器历史纪录中，还可能会保存在Web的日志中。

**GET和POST对服务器的状态**

根据http的设计，大家在看到get的时候，都期望这个请求对服务器没有修改，看到post的时候，都认为这对服务器产生了修改。

**GET幂等，POST不幂等**

幂等是指同一个请求方法执行多次和仅执行一次的效果完全相同。

1.按照RFC规范，PUT，DELETE和安全方法都是幂等的。虽说是规范，但服务端实现是否幂等是无法确保的。

2.引入幂等主要是为了处理同一个请求重复发送的情况，比如在请求响应前失去连接，如果方法是幂等的，就可以放心地重发一次请求。这也是浏览器在后退/刷新时遇到POST会给用户提示的原因：POST语义不是幂等的，重复请求可能会带来意想不到的后果。

3.比如在微博这个场景里，GET的语义会被用在「看看我的Timeline上最新的20条微博」这样的场景，而POST的语义会被用在「发微博、评论、点赞」这样的场景中。

### ★★☆ HTTP 状态码。 

| 分类 | 分类描述 |
| :--- | :--- |
| 1\*\* | 信息，服务器收到请求，需要请求者继续执行操作 |
| 2\*\* | 成功，操作被成功接收并处理 |
| 3\*\* | 重定向，需要进一步的操作以完成请求 |
| 4\*\* | 客户端错误，请求包含语法错误或无法完成请求 |
| 5\*\* | 服务器错误，服务器在处理请求的过程中发生了错误 |

常见HTTP状态码

| 状态码 | 说明 |
| :--- | :--- |
| 200 | 请求成功 |
| 307 | 重定向 |
| 400 | 错误的请求，请求地址或者参数有误 |
| 404 | 请求资源在服务器不存在 |
| 500 | 服务器内部源代码出现错误 |

### ★★★ Cookie 作用、安全性问题、和 Session 的比较。 

Session是在服务端保存的一个数据结构，用来跟踪用户的状态，这个数据可以保存在集群、数据库、文件中。Session 的运行依赖Session ID，而 Session ID 是存在 Cookie 中的。

Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式。

### ★★☆ 缓存 的 Cache-Control 字段，特别是 Expires 和 max-age 的区别。ETag 验证原理。 

####  Cache-Control

可缓存性  
public：http请求返回的过程当中，在cache-control中设置这个值，代表http请求返回的内容所经过的任何路径当中（包括中间一些http代理服务器以及发出请求的客户端浏览器），都可以对返回内容进行缓存操作。  
private：代表只有发起请求的浏览器才可以进行缓存。  
no-cache：可以在本地进行缓存，但每次发请求时，都要向服务器进行验证，如果服务器允许，才能使用本地缓存。  
no-store：本地和代理服务器都不可以存储缓存，每次都要重新请求，拿到内容。  
no-transform：主要是用在proxy服务器，不允许进行格式转换。

#### max-age和Expires

浏览器会先检查缓存是否过期，如果没过期，干脆就不向服务端发起请求，直接使用本地缓存，这叫做“缓存命中”。  
max-age：最大缓存时间  
Expires：有效期  
_这两个同时存在时，max-age优先生效_

#### Etag和Last-Modified

如果没有上一节的两个标签，或者验证失败，则浏览器向服务器发起请求，浏览器通过Etag或Last-Modified判断浏览器缓存的内容是否过期。如果没过期返回304，这叫做“缓存再验证成功”，浏览器更新本地缓存的max-age和Expires，并且使用本地缓存；如果过期了，这叫做“缓存再验证失败（缓存未命中）”，则返回新的数据。  
Etag：被请求变量的实体标记（与客户端请求头 If-None-Match对应）  
Last-Modified：被请求变量的最后修改时间（与客户端请求头If-Modified-Since对应）  
_如果两者都有，就必须同时验证，并且两者都满足才会返回304_

### ★★★ 长连接与短连接原理以及使用场景，流水线。 



**短连接**  
连接-&gt;传输数据-&gt;关闭连接  
比如HTTP是无状态的的短链接，浏览器和服务器每进行一次HTTP操作，就建立一次连接，但任务结束就中断连接。  
具体就是 浏览器client发起并建立TCP连接 -&gt; client发送HttpRequest报文 -&gt; server接收到报文-&gt;server handle并发送HttpResponse报文给前端,发送完毕之后立即调用socket.close方法-&gt;client接收response报文-&gt;client最终会收到server端断开TCP连接的信号-&gt;client 端断开TCP连接，具体就是调用close方法。

也可以这样说：短连接是指SOCKET连接后，发送接收完数据后马上断开连接。  
因为连接后接收了数据就断开了，所以每次数据接受处理不会有联系。 这也是HTTP协议无状态的原因之一。

**长连接**  
连接-&gt;传输数据-&gt;保持连接 -&gt; 传输数据-&gt; ...........-&gt;直到一方关闭连接，多是客户端关闭连接。  
长连接指建立SOCKET连接后不管是否使用都保持连接，但安全性较差。

**HTTP在短链接和长连接上的选择：**

HTTP是无状态的 ，也就是说，浏览器和服务器每进行一次HTTP操作，就建立一次连接，但任务结束就中断连接。如果客户端浏览器访问的某个HTML或其他类型的 Web页中包含有其他的Web资源，如JavaScript文件、图像文件、CSS文件等；当浏览器每遇到这样一个Web资源，就会建立一个HTTP会话

HTTP1.1和HTTP1.0相比较而言，最大的区别就是增加了持久连接支持\(貌似最新的HTTP1.1 可以显示的指定 keep-alive\),但还是无状态的，或者说是不可以信任的。  
如果浏览器或者服务器在其头信息加入了这行代码 Connection:keep-alive  
TCP连接在发送后将仍然保持打开状态，于是，浏览器可以继续通过相同的连接发送请求。保持连接节省了为每个请求建立新连接所需的时间，还节约了带宽。  
实现长连接要客户端和服务端都支持长连接。

**什么时候用长连接，短连接？**  
长连接多用于操作频繁，点对点的通讯，而且连接数不能太多情况，。每个TCP连接都需要三步握手，这需要时间，如果每个操作都是先连接，再操作的话那么处理速度会降低很多，所以每个操作完后都不断开，次处理时直接发送数据包就OK了，不用建立TCP连接。例如：数据库的连接用长连接， 如果用短连接频繁的通信会造成socket错误，而且频繁的socket 创建也是对资源的浪费。

而像WEB网站的http服务一般都用短链接，因为长连接对于服务端来说会耗费一定的资源，而像WEB网站这么频繁的成千上万甚至上亿客户端的连接用短连接会更省一些资源，如果用长连接，而且同时有成千上万的用户，如果每个用户都占用一个连接的话，那可想而知吧。所以并发量大，但每个用户无需频繁操作情况下需用短连好。

总之，长连接和短连接的选择要视情况而定。具体网络中的应用的话：  
http 1.0一般就指短连接，smtp,pop3,telnet这种就可以认为是长连接。一般的网络游戏应用都是长连接

### ★★★ HTTP 存在的安全性问题，以及 HTTPs 的加密、认证和完整性保护作用。 

### HTTP的缺点

**1、通信使用明文（不加密），内容可能会被窃听**

因为按照TCP/IP的工作机制，通信内容在通信线路上有可能遭到窥视。即使是经过加密处理的通信，也会被窥探到通信内容，只是无法破解报文信息的含义。

有两种加密方式：

* 通信加密。用SSL建立安全通信路线，服务端和客户端就可以在安全的通信路线上开始通信。
* 通信内容加密。报文首部不加密，报文主体加密。

**2、不验证通信方的身份，可能遭遇伪装**

任何人都可以发送请求，服务器也都会响应。因此会存在以下隐患：

* 无法确定请求发送至目标的服务器是否是伪装的服务器
* 无法确定响应返回到的客户端是否是伪装的客户端
* 无法确定正在通信的双方是否具备访问权限
* 无法确定请求出自何方
* 即使是无意义的请求也会全部接收，会出现DoS攻击

SSL有一种被称为**证书**的手段可以用于确定通信方（服务器和客户端）。

**3、无法证明报文的完整性，可能遭遇篡改**

HTTP协议无法保证通信的报文的完整性。即没有任何办法确认发出的响应/请求和接收到的响应/请求是前后相同的。在传输途中遇中间者拦截并篡改内容的叫**中间人攻击（MITM）**。  
可用MD5和SHA-1等**散列值校验**的方法以及确认文件的**数字签名方法**（以PGP创建的数字签名为例）来保证报文的完整性，但是当PGP和MD5本身被篡改时，报文的完整性依旧无法保证。

### HTTPS=HTTP+加密+认证+完整性保护

HTTPS是身披SSL外壳的HTTP。  
HTTPS只是HTTP的通信接口部分用SSL和TLS协议代替。  
通常HTTP直接和TCP通信，使用SSL之后变成了先和SSL通信再和TCP通信。

**HTTPS采用的是公开密钥和共享密钥两者并用的混合加密机制**

HTTPS是在**交换密钥**时利用**公开密钥**进行加密，**通信报文交换**利用**共享密钥**进行加密。因为公开密钥处理起来比较麻烦，效率较低。

**共享密钥**

加密和解密用**同一个密钥**的加密方式叫共享密钥加密，也叫对称密钥加密。以共享密钥加密必须要把共享密钥和加密的报文以取传给对方，如果加密的报文被攻击密钥也会被截获。

**公开密钥**

公开密钥加密使用**一对非对称密钥**。一把叫私有密钥，一把叫公开密钥。公开密钥是任何人都可以获得的，但是私有密钥是只有自己知道的。发送方利用**公开密钥进行加密**，接收方利用自己的**私有密钥进行解密**，就不需要担心密钥被盗走。  
SSL采用的是**公开密钥加密**的方式进行加密处理。存在**通信慢**和**CPU消耗大导致处理速度变慢**的问题。

**公开密钥存在的问题**

无法证明密钥本身就是货真价实的公开密钥。可以使用**数字证书认证机构**（CA）和其颁布的公开密钥证书确定该公开密钥是值得信赖的。

服务器会向CA提出公开密钥的申请，CA验证过服务器的身份后会对已申请的公开密钥做数字签名，然后将已签名的公开密钥放入密钥证书中绑定。服务器会将密钥证书发给客户端，从而进行以公开密钥加密的通信。

### 为什么不一直使用HTTPS

1、因为加密通信会消耗更多的CPU和资源内存  
2、减少证书购买的开销

### ★★☆ HTTP/1.x 的缺陷，以及 HTTP/2 的特点。 



### ★★★ HTTP/1.1 的特性。 

### ★★☆ HTTP 与 FTP 的比较。

## Socket

★★☆ 五种 IO 模型的特点以及比较。 

★★★ select、poll、epoll 的原理、比较、以及使用场景；epoll 的水平触发与边缘触发。数据库SQL

★★☆ 手写 SQL 语句，特别是连接查询与分组查询。 

★★☆ 连接查询与子查询的比较。 

★★☆ drop、delete、truncate 比较。 

★★☆ 视图的作用，以及何时能更新视图。 

★☆☆ 理解存储过程、触发器等作用。系统原理

★★★ ACID 的作用以及实现原理。 

★★★ 四大隔离级别，以及不可重复读和幻影读的出现原因。 

★★☆ 封锁的类型以及粒度，两段锁协议，隐式和显示锁定。 

★★★ 乐观锁与悲观锁。 

★★★ MVCC 原理，当前读以及快照读，Next-Key Locks 解决幻影读。 

★★☆ 范式理论。 

★★★ SQL 与 NoSQL 的比较。

## MySQL

★★★ B+ Tree 原理，与其它查找树的比较。 

★★★ MySQL 索引以及优化。 

★★★ 查询优化。 

★★★ InnoDB 与 MyISAM 比较。 

★★☆ 水平切分与垂直切分。 

★★☆ 主从复制原理、作用、实现。 

★☆☆ redo、undo、binlog 日志的作用。

## Redis

★★☆ 字典和跳跃表原理分析。 

★★★ 使用场景。 

★★★ 与 Memchached 的比较。 

★☆☆ 数据淘汰机制。 

★★☆ RDB 和 AOF 持久化机制。 

★★☆ 事件驱动模型。 

★☆☆ 主从复制原理。 

★★★ 集群与分布式。 

★★☆ 事务原理。 

★★★ 线程安全问题。

