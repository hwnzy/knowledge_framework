# 后端面试

## 后端面试

## 基础 

### ★★★ 进程与线程的本质区别、以及各自的使用场景。

1. 进程

进程是资源（CPU、内存等）分配的基本单位，它是程序执行时的一个实例。

程序运行时系统就会创建一个进程，并为它分配资源，然后把该进程放入进程就绪队列

进程调度器选中它的时候就会为它分配CPU时间，程序开始真正运行。

1.1 进程的状态和切换

* 就绪状态：进程已获得除处理机以外的所需资源，等待分配处理机资源
* 运行状态：占用处理机资源运行，处于此状态的进程数小于等于CPU数
* 阻塞状态： 进程等待某种条件，在条件满足之前无法执行

操作系统为了控制进程的执行，必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行，这种行为被称为进程切换，任务切换或上下文切换。  


![](../.gitbook/assets/image%20%28102%29.png)

![](../.gitbook/assets/image%20%28103%29.png)

2. 什么是线程

线程是程序执行时的最小单位，它是进程的一个执行流，是CPU调度和分派的基本单位。

一个进程可以由很多个线程组成，线程间共享进程的所有资源，每个线程有自己的堆栈和局部变量。

线程由CPU独立调度执行，在多CPU环境下就允许多个线程同时运行。同样多线程也可以实现并发操作，每个请求分配一个线程来处理。

3. 进行和线程之间的区别

1. 调度 ：在引入线程的操作系统中，线程是调度和分配的基本单位 ，进程是资源拥有的基本单位 。把传统进程的两个属性分开，线程便能轻装运行，从而可 显著地提高系统的并发程度 。在同一进程中，线程的切换不会引起进程的切换；在由一个进程中的线程切换到另一个进程中的线程时，才会引起进程的切换。
2. 并发性 ：在引入线程的操作系统中，不仅进程之间可以并发执行，而且在一个进程中的多个线程之间亦可并发执行，因而使操作系统具有更好的并发性，从而能 更有效地使用系统资源和提高系统吞吐量。
3. 拥有资源 ：不论是传统的操作系统，还是设有线程的操作系统，进程都是拥有资源的一个独立单位，它可以拥有自己的资源。一般地说，线程自己不拥有系统资源（只有一些必不可少的资源，但它可以访问其隶属进程的资源。
4. 系统开销：由于在创建或撤消进程时，系统都要为之分配或回收资源，因此，操作系统所付出的开销将显著地大于在创建或撤消线程时的开销。进程切换的开销也远大于线程切换的开销。
5. 通信：进程间通信IPC，线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性，因此共享简单。但是线程的数据同步要比进程略复杂。

4. 进行和线程之间的相同点

进程和线程都有ID/寄存器组、状态和优先权、信息块，创建后都可更改自己的属性，都可与父进程共享资源、都不能直接访问其他无关进程或线程的资源

5. 进程和线程的使用场景

有了以上进程和线程的异同点，不难得出结论：

1. 需要频繁创建销毁的优先使用线程；因为对进程来说创建和销毁一个进程代价是很大的。
2. 线程的切换速度快，所以在需要大量计算，切换频繁时用线程，还有耗时的操作使用线程可提高应用程序的响应
3. 因为对CPU系统的效率使用上线程更占优，所以可能要发展到多机分布的用进程，多核分布用线程；
4. 并行操作时使用线程，如C/S架构的服务器端并发线程响应用户的请求；
5. 需要更稳定安全时，适合选择进程；需要速度时，选择线程更好。

### ★☆☆ 进程状态。 

* 就绪状态：进程已获得除处理机以外的所需资源，等待分配处理机资源
* 运行状态：占用处理机资源运行，处于此状态的进程数小于等于CPU数
* 阻塞状态： 进程等待某种条件，在条件满足之前无法执行

操作系统为了控制进程的执行，必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行，这种行为被称为进程切换，任务切换或上下文切换。

### ★★★ 进程调度算法的特点以及使用场景。 

1、时间片轮转调度算法（RR）：给每个进程固定的执行时间，根据进程到达的先后顺序让进程在单位时间片内执行，执行完成后便调度下一个进程执行，时间片轮转调度不考虑进程等待时间和执行时间，属于抢占式调度。优点是兼顾长短作业；缺点是平均等待时间较长，上下文切换较费时。适用于分时系统。

2、先来先服务调度算法（FCFS）：根据进程到达的先后顺序执行进程，不考虑等待时间和执行时间，会产生饥饿现象。属于非抢占式调度，优点是公平，实现简单；缺点是不利于短作业。

3、优先级调度算法（HPF）：在进程等待队列中选择优先级最高的来执行。常被用于批处理系统中，还可用于实时系统中。

4、多级反馈队列调度算法：将时间片轮转与优先级调度相结合，把进程按优先级分成不同的队列，先按优先级调度，优先级相同的，按时间片轮转。优点是兼顾长短作业，有较好的响应时间，可行性强，适用于各种作业环境。

5、高响应比优先调度算法：根据“响应比=（进程执行时间+进程等待时间）/ 进程执行时间”这个公式得到的响应比来进行调度。高响应比优先算法在等待时间相同的情况下，作业执行的时间越短，响应比越高，满足段任务优先，同时响应比会随着等待时间增加而变大，优先级会提高，能够避免饥饿现象。优点是兼顾长短作业，缺点是计算响应比开销大，适用于批处理系统。

### ★☆☆ 线程实现的方式。 

线程的3种实现方式

在引入线程的操作系统中，进程是资源分配的基本单位，线程是独立调度的基本单位。在同一进程中，线程的切换不会引起进程切换。在不同进程中进行线程切换,如从一个进程内的线程切换到另一个进程中的线程时，会引起进程切换。

线程分为两种：

| 名称 | 描述 |
| :--- | :--- |
| 用户级线程\(User-Level Thread, ULT\) | 由应用程序所支持的线程实现, 对内核不可见 |
| 内核级线程\(Kernel-Level Thread, KLT\) | 内核级线程又称为内核支持的线程 |

组合线程\(Hybrid Multithreading\)是一种别的实现方式而不是线程的种类。

### ★★☆ 协程的作用。 

1.协程的含义和实现

协程是单进程单线程的超越函数的调度机制，它通过一定的调度手段进行调度。

（Python使用generator机制，greenlet使用汇编控制对程序指向来实现）。

2.协程有什么作用

计算机分为IO bound 和CPU bound两种类型的task。在这两种情况中，协程都没有什么作用。

为什么？

在CPU bound task中，cpu被用来执行任务去了。这类task，即使一个一个方法的执行，跟协程的效率还要高出一点点，使用协程没有意义。IO bound task中，CPU已经陷入系统调用之中，用户空间的调度无论如何也是没有CPU的，这样情况下，协程只能死死的。在这样情况下，祈求高效率，怎么可能。

协程只有在非常有限制的情况下，才有一些用处，在单进程单线程任务中的交互青霞，才有它的用武之地。

3.协程不是未来（反驳赖勇浩）。协程是很早之前就有的。很早之前，windows就有纤程的概念，Linux不太确定。但是它一直作为小众的API而存在。

4.gevnet+flask是一个很流行的用法，但是gevent真正有用的是libev，它是使用epoll\(linux\), kqueue\(bsd\),IOCP\(windows\)实现network IO，并在轮询处理signal，signal，callback的lib。

### ★★☆ 常见进程同步问题。 

 生产者-消费者（三个信号量）

empty：缓冲区 空闲 资源数，full：缓冲区 已满 资源数 ： 保证不会空时消费，满时生产（保证顺序、同步） mutex 代表互斥锁 ： 保证同一时间只有一个线程可以访问共享资源（互斥访问）

 读者-写者问题 （可以多个进程同时读，但是写时就只能有一个写）

wmutex： 互斥的写 （写时不能读，只能一个写） rmutex： 互斥的使用readcount（对readcount加锁） readcount： 统计读进程数目，及读者数量（临界资源，多个读进程共享）

 哲学家进餐问题 ： 只允许同时拿起左右两边的筷子

mutex: 互斥量，对拿起左右两只筷子加锁（只有一个进程能访问）

### ★★★ 进程通信方法的特点以及使用场景。

一、共享内存通信

共享内存是指多个进程共享一块内存，是专门用来解决不同进程之间的通信问题的，由于是直接对内存进行数据传输操作，所以是速度最快的IPC（inter-process communication）方式，因为是共享内存，所以需要配合信号量机制实现同步。

二、管道通信

无名管道\( pipe \)：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。

当一个管道建立时，它会创建两个文件描述符：`fd[0]`为读而打开，`fd[1]`为写而打开。如下图：

![](https://img-blog.csdnimg.cn/20190731095842458.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM5NTA3NzIz,size_16,color_FFFFFF,t_70)

高级管道\(popen\)：将另一个程序当做一个新的进程在当前程序进程中启动，则它算是当前程序的子进程，这种方式我们成为高级管道方式。

有名管道 \(named pipe\) ： 有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。

三、消息队列通信

消息队列\( message queue \) ： 消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。

四、套接字通信

套接字\( socket \) ： 套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同机器间的进程通信。

### ★★★ 死锁必要条件、解决死锁策略，能写出和分析死锁的代码，能说明在数据库管理系统或者 Java 中如何解决死锁。 

必要条件：

互斥条件（Mutual exclusion）：资源不能被共享，只能由一个进程使用。 

请求与保持条件（Hold and wait）：已经得到资源的进程可以再次申请新的资源。 

不可剥夺剥夺条件（No pre-emption）：已经分配的资源不能从相应的进程中被强制地剥夺。 

环路等待条件（Circular wait）：系统中若干进程组成环路，该环路中每个进程都在等待相邻进程正占用的资源。

解决策略：

1\) 死锁预防：预先静态分配法：破坏了“不可剥夺条件”，资源有序分配法：破坏了“环路条件”

2）死锁避免：设法破坏4个必要条件之一，严格防止死锁的发生。银行家算法：若发现分配资源后进入不安全状态，则不予分配；若扔处于安全状态，则实施分配。

3）死锁检测：允许死锁产生，定时地运行一个死锁检测程序，判断系统是否发生死锁。

4）死锁解除：资源剥夺法，撤销进程法

### ★★★ 虚拟内存的作用，分页系统实现虚拟内存原理。 

虚拟内存是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。 

虚拟地址被分成虚拟页号（高地址）和偏移量（低地址）两部分。不同的划分对应了不同的页面大小。

 虚拟页号可作为页表的索引，以找到该虚拟页面对应的页表项。由页表项可以找到对应的页框。然后把页框号拼接到偏移量的高位端，以替换调虚拟页号，形成送往内存的物理地址。 

### ★★★ 页面置换算法的原理，特别是 LRU 的实现原理，最好能手写，再说明它在 Redis 等作为缓存置换算法。 

LRU（Least recently used，最近最少使用）

LRU算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。

基本思路

1. 新数据插入到列表头部；
2. 每当缓存命中（即缓存数据被访问），则将数据移到列表头部；
3. 当列表满的时候，将列表尾部的数据丢弃。

```python
class DLinkedNode:
    def __init__(self, key=0, value=0):
        self.key = key
        self.value = value
        self.prev = None
        self.next = None


class LRUCache:

    def __init__(self, capacity: int):
        self.cache = dict()
        # 使用伪头部和伪尾部节点    
        self.head = DLinkedNode()
        self.tail = DLinkedNode()
        self.head.next = self.tail
        self.tail.prev = self.head
        self.capacity = capacity
        self.size = 0

    def get(self, key: int) -> int:
        if key not in self.cache:
            return -1
        # 如果 key 存在，先通过哈希表定位，再移到头部
        node = self.cache[key]
        self.moveToHead(node)
        return node.value

    def put(self, key: int, value: int) -> None:
        if key not in self.cache:
            # 如果 key 不存在，创建一个新的节点
            node = DLinkedNode(key, value)
            # 添加进哈希表
            self.cache[key] = node
            # 添加至双向链表的头部
            self.addToHead(node)
            self.size += 1
            if self.size > self.capacity:
                # 如果超出容量，删除双向链表的尾部节点
                removed = self.removeTail()
                # 删除哈希表中对应的项
                self.cache.pop(removed.key)
                self.size -= 1
        else:
            # 如果 key 存在，先通过哈希表定位，再修改 value，并移到头部
            node = self.cache[key]
            node.value = value
            self.moveToHead(node)
    
    def addToHead(self, node):
        node.prev = self.head
        node.next = self.head.next
        self.head.next.prev = node
        self.head.next = node
    
    def removeNode(self, node):
        node.prev.next = node.next
        node.next.prev = node.prev

    def moveToHead(self, node):
        self.removeNode(node)
        self.addToHead(node)

    def removeTail(self):
        node = self.tail.prev
        self.removeNode(node)
        return node
```

### ★★★ 比较分页与分段的区别。 

1 页是信息的物理单位，分页是为了实现离散分配方式，以消减内存的外零头，提高内存的利用率。分页仅仅是由于系统管理的需要而不是用户的需要

   段是信息的逻辑单位，分段的目的是为了能更好地满足用户的需要

2 页的大小固定，由系统把逻辑地址划分为页号和页内地址两部分，段的长度却不固定，决定于用户所编写的程序

3 分页的作业地址空间是一维的，即单一的线性地址空间。 分段的作业地址空间是二维的 在标识一个地址时，即需给出段名，又需给出段内地址

### ★★★ 分析静态链接的不足，以及动态链接的特点。

1 静态链接库的优点 

 \(1\) 代码装载速度快，执行速度略比动态链接库快； 

 \(2\) 只需保证在开发者的计算机中有正确的.LIB文件，在以二进制形式发布程序时不需考虑在用户的计算机上.LIB文件是否存在及版本问题，可避免DLL地狱等问题。 

2 动态链接库的优点 

 \(1\) 更加节省内存并减少页面交换；

 \(2\) DLL文件与EXE文件独立，只要输出接口不变（即名称、参数、返回值类型和调用约定不变），更换DLL文件不会对EXE文件造成任何影响，因而极大地提高了可维护性和可扩展性；

 \(3\) 不同编程语言编写的程序只要按照函数调用约定就可以调用同一个DLL函数；

 \(4\)适用于大规模的软件开发，使开发过程独立、耦合度小，便于不同开发者和开发组织之间进行开发和测试

3 不足之处

 \(1\) 使用静态链接生成的可执行文件体积较大，包含相同的公共代码，造成浪费；

 \(2\) 使用动态链接库的应用程序不是自完备的，它依赖的DLL模块也要存在，如果使用载入时动态链接，程序启动时发现DLL不存在，系统将终止程序并给出错误信息。而使用运行时动态链接，系统不会终止，但由于DLL中的导出函数不可用，程序会加载失败；速度比静态链接慢。当某个模块更新后，如果新模块与旧的模块不兼容，那么那些需要该模块才能运行的软件，统统撕掉。这在早期Windows中很常见。

## Linux

### ★★☆ 文件系统的原理，特别是 inode 和 block。数据恢复原理。 

磁盘要分区，然后格式化，创建文件系统。

在每个linux存储设备或存储设备的分区被格式化为ext4文件系统后，一般都有两部分：

第一部分是INode。inode包含的属性信息包括文件大小、属性、归属的用户组，读写权限、文件类型、修改时间，还包含指向文件实体的指针的功能。（文件名不属于文件的属性，inode不包含文件名）

第二部分是block。Block用来存储实际数据的，例如照片，视频等普通文件数据。

数据恢复原理：删除的数据并没有被删除，只是标记为此处空闲，可以写入数据。

### ★★★ 硬链接与软链接的区别。

![](../.gitbook/assets/image%20%28100%29.png)

###  ★★☆ 能够使用常用的命令，比如 cat 文件内容查看、find 搜索文件，以及 cut、sort 等管线命令。了解 grep 和 awk 的作用。 

cat 文件名 查看文件内容内容 -n 列出行号

find 查找位置 -name 文件名

grep 主要用于搜索某些字符串 sed，awk 用于处理文本

### ★★★ 僵尸进程与孤儿进程的区别，从 SIGCHLD 分析产生僵尸进程的原因。

 **僵尸进程：**一个子进程在其父进程还没有来得及调用wait\(\)或waitpid\(\)来获取子进程的信号状态的情况下退出，那么这个子进程就是僵尸进程。子进程结束后会向父进程发出SIGCHLD信号。  
  
**孤儿进程：**一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程\(进程号为1\)所收养，并由init进程对它们完成状态收集工作。  




## 网络基础

### ★★★ 各层协议的作用，以及 TCP/IP 协议的特点。 

![](../.gitbook/assets/image%20%2899%29.png)

### ★★☆ 以太网的特点，以及帧结构。 

### ★★☆ 集线器、交换机、路由器的作用，以及所属的网络层。 

### ★★☆ IP 数据数据报常见字段的作用。 

### ★☆☆ ARP 协议的作用，以及维护 ARP 缓存的过程。 

### ★★☆ ICMP 报文种类以及作用；和 IP 数据报的关系；Ping 和 Traceroute 的具体原理。 

### ★★★ UDP 与 TCP 比较，分析上层协议应该使用 UDP 还是 TCP。 

1）TCP 是面向连接的传输。UDP 是无连接的传输

2）TCP 有流量控制、拥塞控制，检验数据数据按序到达，而 UDP 则相反。

3）TCP 的路由选择只发生在建立连接的时候，而 UDP 的每个报文都要进行路由选择

4）TCP 是可靠性传输，他的可靠性是由超时重发机制实现的，而 UDP则是不可靠传输

5）UDP 因为少了很多控制信息，所以传输速度比 TCP 速度快

6）TCP 适合用于传输大量数据，UDP 适合用于传输小量数据  
  
数据丢失，某些应用（例如audio）可以容忍某种程度上的数据丢失；而其他应用 （例如文件传输、telnet）要求100%可靠的数据传输。

实时性，某些应用（例如IP电话、交互式游戏等）要求较低的时延。

带宽，某些应用（例如多媒体）对最低带宽有要求；而其他应用（“弹性应用”）则可灵活应用所能得到的带宽。

### ★★★ 理解三次握手以及四次挥手具体过程，三次握手的原因、四次挥手原因、TIME\_WAIT 的作用。 

**三次握手**

第一次握手：客户端给服务端发一个 SYN 报文，并指明客户端的初始化序列号a。

第二次握手：服务器收到客户端的 SYN 报文之后，会以自己的 SYN 报文作为应答，并且也是指定了自己的初始化序列号 b。同时会把客户端的 a +1 作为ACK 的值

第三次握手：客户端收到 SYN 报文之后，会发送一个 ACK 报文，当然，也是一样把服务器的 b + 1 作为 ACK 的值，表示已经收到了服务端的 SYN 报文

在socket编程中，客户端执行connect\(\)时，将触发三次握手。

 **为什么需要三次握手，两次不行吗？**

如客户端发出连接请求，但因连接请求报文丢失而未收到确认，于是客户端再重传一次连接请求。后来收到了确认，建立了连接。数据传输完毕后，就释放了连接，客户端共发出了两个连接请求报文段，其中第一个丢失，第二个到达了服务端，但是第一个丢失的报文段只是在某些网络结点长时间滞留了，延误到连接释放以后的某个时间才到达服务端，此时服务端误认为客户端又发出一次新的连接请求，于是就向客户端发出确认报文段，同意建立连接，不采用三次握手，只要服务端发出确认，就建立新的连接了，此时客户端忽略服务端发来的确认，也不发送数据，则服务端一致等待客户端发送数据，浪费资源。

**四次挥手**

_注意: 中断连接端可以是客户端，也可以是服务器端. 下面仅以客户端断开连接举例, 反之亦然._

1. 客户端发送一个数据分段, 其中的 FIN 标记设置为1. 客户端进入 FIN-WAIT 状态. 该状态下客户端只接收数据, 不再发送数据.
2. 服务器接收到带有 FIN = 1 的数据分段, 发送带有 ACK = 1 的剩余数据分段, 确认收到客户端发来的 FIN 信息.
3. 服务器等到所有数据传输结束, 向客户端发送一个带有 FIN = 1 的数据分段, 并进入 CLOSE-WAIT 状态, 等待客户端发来带有 ACK = 1 的确认报文.
4. 客户端收到服务器发来带有 FIN = 1 的报文, 返回 ACK = 1 的报文确认, 为了防止服务器端未收到需要重发, 进入 TIME-WAIT 状态. 服务器接收到报文后关闭连接. 客户端等待 2MSL 后未收到回复, 则认为服务器成功关闭, 客户端关闭连接.

 **挥手为什么需要四次？**

因为当服务端收到客户端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当服务端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉客户端，“你发的FIN报文我收到了”。只有等到我服务端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四次挥手。

**TIME\_WAIT 的作用**

* 保证客户端发送的最后一个ACK报文段能够到达服务端。

这个ACK报文段有可能丢失，使得处于LAST-ACK状态的B收不到对已发送的FIN+ACK报文段的确认，服务端超时重传FIN+ACK报文段，而客户端能在2MSL时间内收到这个重传的FIN+ACK报文段，接着客户端重传一次确认，重新启动2MSL计时器，最后客户端和服务端都进入到CLOSED状态，若客户端在TIME-WAIT状态不等待一段时间，而是发送完ACK报文段后立即释放连接，则无法收到服务端重传的FIN+ACK报文段，所以不会再发送一次确认报文段，则服务端无法正常进入到CLOSED状态。

* 防止“已失效的连接请求报文段”出现在本连接中。

客户端在发送完最后一个ACK报文段后，再经过2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失，使下一个新的连接中不会出现这种旧的连接请求报文段。  


### ★★★ 可靠传输原理，并设计可靠 UDP 协议。 

### ★★☆ TCP 拥塞控制的作用，理解具体原理。 

### ★★☆ DNS 的端口号；TCP 还是 UDP；作为缓存、负载均衡。

## HTTP

### ★★★ GET 与 POST 比较：作用、参数、安全性、幂等性、可缓存。 

GET

1.GET是通过URL提交数据，因此GET可提交的数据量就跟URL所能达到的最大长度有直接关系。

2.实际上HTTP协议对URL长度是没有限制的；限制URL长度大多数是浏览器或者服务器的配置参数

POST

1.同样的，HTTP协议没有对POST进行任何限制，一般是受服务器配置限制或者内存大小。

2.PHP下可以修改php.conf的postmaxsize来设置POST的大小。

**请求header的content-length问题**

如果有人恶意伪造content-length很大的包头，但实际上发送content-length很小的请求，这样服务器会一直干等，直到超时。当然服务器是可以通过设置来避免该问题的

**GET和POST的安全性**

1.GET是通过URL方式请求，可以直接看到，明文传输。

2.POST是通过请求header请求，可以开发者工具或者抓包可以看到，同样也是明文的。 3.GET请求会保存在浏览器历史纪录中，还可能会保存在Web的日志中。

**GET和POST对服务器的状态**

根据http的设计，大家在看到get的时候，都期望这个请求对服务器没有修改，看到post的时候，都认为这对服务器产生了修改。

**GET幂等，POST不幂等**

幂等是指同一个请求方法执行多次和仅执行一次的效果完全相同。

1.按照RFC规范，PUT，DELETE和安全方法都是幂等的。虽说是规范，但服务端实现是否幂等是无法确保的。

2.引入幂等主要是为了处理同一个请求重复发送的情况，比如在请求响应前失去连接，如果方法是幂等的，就可以放心地重发一次请求。这也是浏览器在后退/刷新时遇到POST会给用户提示的原因：POST语义不是幂等的，重复请求可能会带来意想不到的后果。

3.比如在微博这个场景里，GET的语义会被用在「看看我的Timeline上最新的20条微博」这样的场景，而POST的语义会被用在「发微博、评论、点赞」这样的场景中。

### ★★☆ HTTP 状态码。 

| 分类 | 分类描述 |
| :--- | :--- |
| 1\*\* | 信息，服务器收到请求，需要请求者继续执行操作 |
| 2\*\* | 成功，操作被成功接收并处理 |
| 3\*\* | 重定向，需要进一步的操作以完成请求 |
| 4\*\* | 客户端错误，请求包含语法错误或无法完成请求 |
| 5\*\* | 服务器错误，服务器在处理请求的过程中发生了错误 |

常见HTTP状态码

| 状态码 | 说明 |
| :--- | :--- |
| 200 | 请求成功 |
| 307 | 重定向 |
| 400 | 错误的请求，请求地址或者参数有误 |
| 404 | 请求资源在服务器不存在 |
| 500 | 服务器内部源代码出现错误 |

### ★★★ Cookie 作用、安全性问题、和 Session 的比较。 

Session是在服务端保存的一个数据结构，用来跟踪用户的状态，这个数据可以保存在集群、数据库、文件中。Session 的运行依赖Session ID，而 Session ID 是存在 Cookie 中的。

Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式。

### ★★☆ 缓存 的 Cache-Control 字段，特别是 Expires 和 max-age 的区别。ETag 验证原理。 

####  Cache-Control

可缓存性  
public：http请求返回的过程当中，在cache-control中设置这个值，代表http请求返回的内容所经过的任何路径当中（包括中间一些http代理服务器以及发出请求的客户端浏览器），都可以对返回内容进行缓存操作。  
private：代表只有发起请求的浏览器才可以进行缓存。  
no-cache：可以在本地进行缓存，但每次发请求时，都要向服务器进行验证，如果服务器允许，才能使用本地缓存。  
no-store：本地和代理服务器都不可以存储缓存，每次都要重新请求，拿到内容。  
no-transform：主要是用在proxy服务器，不允许进行格式转换。

#### max-age和Expires

浏览器会先检查缓存是否过期，如果没过期，干脆就不向服务端发起请求，直接使用本地缓存，这叫做“缓存命中”。  
max-age：最大缓存时间  
Expires：有效期  
_这两个同时存在时，max-age优先生效_

#### Etag和Last-Modified

如果没有上一节的两个标签，或者验证失败，则浏览器向服务器发起请求，浏览器通过Etag或Last-Modified判断浏览器缓存的内容是否过期。如果没过期返回304，这叫做“缓存再验证成功”，浏览器更新本地缓存的max-age和Expires，并且使用本地缓存；如果过期了，这叫做“缓存再验证失败（缓存未命中）”，则返回新的数据。  
Etag：被请求变量的实体标记（与客户端请求头 If-None-Match对应）  
Last-Modified：被请求变量的最后修改时间（与客户端请求头If-Modified-Since对应）  
_如果两者都有，就必须同时验证，并且两者都满足才会返回304_

### ★★★ 长连接与短连接原理以及使用场景，流水线。 



**短连接**  
连接-&gt;传输数据-&gt;关闭连接  
比如HTTP是无状态的的短链接，浏览器和服务器每进行一次HTTP操作，就建立一次连接，但任务结束就中断连接。  
具体就是 浏览器client发起并建立TCP连接 -&gt; client发送HttpRequest报文 -&gt; server接收到报文-&gt;server handle并发送HttpResponse报文给前端,发送完毕之后立即调用socket.close方法-&gt;client接收response报文-&gt;client最终会收到server端断开TCP连接的信号-&gt;client 端断开TCP连接，具体就是调用close方法。

也可以这样说：短连接是指SOCKET连接后，发送接收完数据后马上断开连接。  
因为连接后接收了数据就断开了，所以每次数据接受处理不会有联系。 这也是HTTP协议无状态的原因之一。

**长连接**  
连接-&gt;传输数据-&gt;保持连接 -&gt; 传输数据-&gt; ...........-&gt;直到一方关闭连接，多是客户端关闭连接。  
长连接指建立SOCKET连接后不管是否使用都保持连接，但安全性较差。

**HTTP在短链接和长连接上的选择：**

HTTP是无状态的 ，也就是说，浏览器和服务器每进行一次HTTP操作，就建立一次连接，但任务结束就中断连接。如果客户端浏览器访问的某个HTML或其他类型的 Web页中包含有其他的Web资源，如JavaScript文件、图像文件、CSS文件等；当浏览器每遇到这样一个Web资源，就会建立一个HTTP会话

HTTP1.1和HTTP1.0相比较而言，最大的区别就是增加了持久连接支持\(貌似最新的HTTP1.1 可以显示的指定 keep-alive\),但还是无状态的，或者说是不可以信任的。  
如果浏览器或者服务器在其头信息加入了这行代码 Connection:keep-alive  
TCP连接在发送后将仍然保持打开状态，于是，浏览器可以继续通过相同的连接发送请求。保持连接节省了为每个请求建立新连接所需的时间，还节约了带宽。  
实现长连接要客户端和服务端都支持长连接。

**什么时候用长连接，短连接？**  
长连接多用于操作频繁，点对点的通讯，而且连接数不能太多情况，。每个TCP连接都需要三步握手，这需要时间，如果每个操作都是先连接，再操作的话那么处理速度会降低很多，所以每个操作完后都不断开，次处理时直接发送数据包就OK了，不用建立TCP连接。例如：数据库的连接用长连接， 如果用短连接频繁的通信会造成socket错误，而且频繁的socket 创建也是对资源的浪费。

而像WEB网站的http服务一般都用短链接，因为长连接对于服务端来说会耗费一定的资源，而像WEB网站这么频繁的成千上万甚至上亿客户端的连接用短连接会更省一些资源，如果用长连接，而且同时有成千上万的用户，如果每个用户都占用一个连接的话，那可想而知吧。所以并发量大，但每个用户无需频繁操作情况下需用短连好。

总之，长连接和短连接的选择要视情况而定。具体网络中的应用的话：  
http 1.0一般就指短连接，smtp,pop3,telnet这种就可以认为是长连接。一般的网络游戏应用都是长连接

### ★★★ HTTP 存在的安全性问题，以及 HTTPs 的加密、认证和完整性保护作用。 

HTTP的缺点

**1、通信使用明文（不加密），内容可能会被窃听**

因为按照TCP/IP的工作机制，通信内容在通信线路上有可能遭到窥视。即使是经过加密处理的通信，也会被窥探到通信内容，只是无法破解报文信息的含义。

有两种加密方式：

* 通信加密。用SSL建立安全通信路线，服务端和客户端就可以在安全的通信路线上开始通信。
* 通信内容加密。报文首部不加密，报文主体加密。

**2、不验证通信方的身份，可能遭遇伪装**

任何人都可以发送请求，服务器也都会响应。因此会存在以下隐患：

* 无法确定请求发送至目标的服务器是否是伪装的服务器
* 无法确定响应返回到的客户端是否是伪装的客户端
* 无法确定正在通信的双方是否具备访问权限
* 无法确定请求出自何方
* 即使是无意义的请求也会全部接收，会出现DoS攻击

SSL有一种被称为**证书**的手段可以用于确定通信方（服务器和客户端）。

**3、无法证明报文的完整性，可能遭遇篡改**

HTTP协议无法保证通信的报文的完整性。即没有任何办法确认发出的响应/请求和接收到的响应/请求是前后相同的。在传输途中遇中间者拦截并篡改内容的叫**中间人攻击（MITM）**。  
可用MD5和SHA-1等**散列值校验**的方法以及确认文件的**数字签名方法**（以PGP创建的数字签名为例）来保证报文的完整性，但是当PGP和MD5本身被篡改时，报文的完整性依旧无法保证。

HTTPS=HTTP+加密+认证+完整性保护

HTTPS是身披SSL外壳的HTTP。  
HTTPS只是HTTP的通信接口部分用SSL和TLS协议代替。  
通常HTTP直接和TCP通信，使用SSL之后变成了先和SSL通信再和TCP通信。

**HTTPS采用的是公开密钥和共享密钥两者并用的混合加密机制**

HTTPS是在**交换密钥**时利用**公开密钥**进行加密，**通信报文交换**利用**共享密钥**进行加密。因为公开密钥处理起来比较麻烦，效率较低。

**共享密钥**

加密和解密用**同一个密钥**的加密方式叫共享密钥加密，也叫对称密钥加密。以共享密钥加密必须要把共享密钥和加密的报文以取传给对方，如果加密的报文被攻击密钥也会被截获。

**公开密钥**

公开密钥加密使用**一对非对称密钥**。一把叫私有密钥，一把叫公开密钥。公开密钥是任何人都可以获得的，但是私有密钥是只有自己知道的。发送方利用**公开密钥进行加密**，接收方利用自己的**私有密钥进行解密**，就不需要担心密钥被盗走。  
SSL采用的是**公开密钥加密**的方式进行加密处理。存在**通信慢**和**CPU消耗大导致处理速度变慢**的问题。

**公开密钥存在的问题**

无法证明密钥本身就是货真价实的公开密钥。可以使用**数字证书认证机构**（CA）和其颁布的公开密钥证书确定该公开密钥是值得信赖的。

服务器会向CA提出公开密钥的申请，CA验证过服务器的身份后会对已申请的公开密钥做数字签名，然后将已签名的公开密钥放入密钥证书中绑定。服务器会将密钥证书发给客户端，从而进行以公开密钥加密的通信。

为什么不一直使用HTTPS

1、因为加密通信会消耗更多的CPU和资源内存  
2、减少证书购买的开销

### ★★☆ HTTP/1.x 的缺陷，以及 HTTP/2 的特点。 

**为什么要减少http请求**  
 这就要是要深入了解http1.x了

首先浏览器能够针对同一个域名能够发起的tcp请求是有限制的，像Chorme同时只支持发起6个tcp请求，意味着超过6个就有一些请求必须排队，这意味着请求会出现排队阻塞，而且虽然一个tcp连接可以发起多个请求但是如果其中某个请求很慢，还会让排队中的请求一起堵塞那么长时间。总结就是**请求连接数量有限然后请求会排队阻塞**

**同样原因的其他优化方法**

* 小图片内嵌在html中，以data base64格式存放图片。
* 把多个小的js文件合并成为一个大js文件,css也可以这样处理，不过这里要平缓，考虑缓存的问题，大文件里可能有些经常更新 有些不经常更新 要区别等待。

开始正式介绍http1.x的缺点

* 1.请求阻塞 如上已清晰说明
* 2.以明文文本字符串的形式传输内容，存在安全问题。
* 3.http 请求头无状态特性 导致传输效率低下  多个http请求头大部分信息是相同的，重复传输，导致宽带浪费.请求头多达几百字节，而请求主体却只有十几个字节，有效信息比很低。
* 4.只能浏览器主动请求响应，不能服务器主动推送信息过来

http2优势

**http2基于sdpy协议 ，专注于性能，目标是在用户和服务器间只用一个连接**  
 sdpy协议是google2009研发出来的，主要就是为了解决http1效率不高的问题

* 1.二进制帧数据  http2采用二进制进行数据传输，它把原来的header+body的数据格式拆分为一帧帧的二进制数据进行发送，而且收发都是无顺序的，这意味着不会出现堵塞。一帧帧数据上有个标识id,能够区分数据 ，浏览器可以据此组合出数据
* 2.header头数据压缩，和同一域名请求，只发送请求头不同的部分，这样就解决了http1中的问题 请求头过大而且重复发送
* 3.支持服务器端推送技术
* 4.传输内容加密  http2不强制加密，但是chrome firefox都公开宣布只支持加密的http2 所以实事上http2是加密的

http2缺点

主要是底层支持的tcp协议造成的问题

* tcp 以及tcp+tls建立连接延时，两个握手延时
* tcp队头阻塞

http2.0和http1.x的区别:

1. http1的解析是基于文本协议的各式解析,而http2.0的协议解析是二进制格式,更加的强大
2. **多路复用\(Mutiplexing\) :** 一个连接上可以有多个request,且可以随机的混在一起,每个不同的request都有对应的id,服务端可以通过request\_id来辨别,大大加快了传输速率
3. header压缩: http1.x中的header需要携带大量信息.而且每次都要重复发送.http2.0使用encode来减少传输的header大小.而且客户端和服务端可以各自缓存\(cache\)一份header filed表,避免了header的重复传输,还可以减少传输的大小.
4. 服务端推送\(server push\): 可以通过解析html中的依赖,智能地返回所需的其他文件\(css或者js等\),而不用再发起一次请求.

### ★★★ HTTP/1.1 的特性。 

**HTTP1.0和HTTP1.1的一些区别**

HTTP1.0最早在网页中使用是在1996年，那个时候只是使用一些较为简单的网页上和网络请求上，而HTTP1.1则在1999年才开始广泛应用于现在的各大浏览器网络请求中，同时HTTP1.1也是当前使用最为广泛的HTTP协议。 主要区别主要体现在：

1. **缓存处理**，在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。
2. **带宽优化及网络连接的使用**，HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。
3. **错误通知的管理**，在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。
4. **Host头处理**，在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）。
5. **长连接**，HTTP 1.1支持长连接（PersistentConnection）和请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启Connection： keep-alive，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。

### ★★☆ HTTP 与 FTP 的比较。

![](../.gitbook/assets/image%20%28104%29.png)

## Socket

### ★★☆ 五种 IO 模型的特点以及比较。 

1.阻塞式IO

* 使用系统调用，并一直阻塞知道内核将数据准备好，之后再由内核缓冲区复制到用户态，在等待内核准备的这段时间什么也干不了
* 特点：在I/O执行的两个阶段都被阻塞了--阻塞等待数据，阻塞拷贝数据
* 如图

![](https://img-blog.csdnimg.cn/20190821112547157.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNjUwOTYxMg==,size_16,color_FFFFFF,t_70)

2.非阻塞式IO

* 内核在没有准备好数据的时候会返回错误码，而调用程序不会休眠，而是不断轮询询问内核数据是否准备好
* 特点：在I/O执行的第一个阶段不会阻塞线程，但在第二阶段会阻塞
* 如图

![](https://img-blog.csdnimg.cn/20190821112532720.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNjUwOTYxMg==,size_16,color_FFFFFF,t_70)

3.IO多路复用

* 类似非阻塞，只不过轮询不是由用户线程去执行，而是由内核去轮询，内核监听程序监听到数据准备好后，调用内核函数复制数据到用户空间
* 特点：进行了两次系统调用，进程先是阻塞在select/poll上，再是阻塞在读操作的第二阶段上
* 如图

![](https://img-blog.csdnimg.cn/2019082111251635.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNjUwOTYxMg==,size_16,color_FFFFFF,t_70)

4. 信号驱动IO

![](https://img-blog.csdnimg.cn/20190821112706247.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNjUwOTYxMg==,size_16,color_FFFFFF,t_70)

* 使用该IO模型，需要开启套接字的信号驱动IO功能，并通过sigaction系统调用安装一个信号处理函数。sigaction函数立即返回，我们的进程继续工作，即进程没有被阻塞。当数据报准备好时，内核会为该进程产生一个SIGION信号，这样我们可以在信号处理函数中调用recvfrom读取数据报
* 特点：在等待数据ready期间进程不被阻塞，当收到信号通知时再阻塞并拷贝数据

5.异步IO

![](https://img-blog.csdnimg.cn/20190821113704807.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNjUwOTYxMg==,size_16,color_FFFFFF,t_70)

* 用户进程在发起aio\_read操作后，该系统调用立即返回--然后内核会自己等待数据ready，并且自动将数据拷贝到用户内存。整个过程完成以后，内核会给用户进程发送一个信号，通知IO操作完成
* 异步IO与信号驱动式IO的主要区别是：信号驱动IO是由内核通知我们何时启动一个IO操作，而异步IO是由内核通知我们IO操作何时完成。
* 特点：IO执行的两个阶段都由内核去完成，用户进程无需干预，也不会被阻塞。

**五种IO模型的比较：**

![](https://img-blog.csdnimg.cn/20190821114230351.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNjUwOTYxMg==,size_16,color_FFFFFF,t_70)

* 同步I/O操作：导致请求进程阻塞，直到I/O操作完成。
* 异步I/O操作：不导致请求进程阻塞。

综上：阻塞式IO、非阻塞式IO、信号驱动IO、IO复用都是同步IO模型。因为其中真正的IO操作将阻塞进程。

只有异步I/O模型属于POSIX定义的**异步I/O**，因为在异步I/O模型中，用户进程是将整个I/O操作都交给内核来完成，内核完成后发信号通知，在此期间用户进程完全不用去理会。

### ★★★ select、poll、epoll 的原理、比较、以及使用场景；epoll 的水平触发与边缘触发。

epoll和select

> 假设你在大学读书，住的宿舍楼有很多间房间，你的朋友要来找你。 select版宿管大妈就会带着你的朋友挨个房间去找，直到找到你为止。 而epoll版宿管大妈会先记下每位同学的房间号， 你的朋友来时，只需告诉你的朋友你住在哪个房间即可，不用亲自带着你的朋友满大楼找人。 如果来了10000个人，都要找自己住这栋楼的同学时，select版和epoll版宿管大妈，谁的效率更高，不言自明。 同理，在高并发服务器中，轮询I/O是最耗时间的操作之一，select和epoll的性能谁的性能更高，同样十分明了。  
>  select的调用复杂度是线性的，即O\(n\)。举个例子，一个保姆照看一群孩子，如果把孩子是否需要尿尿比作网络IO事件，select的作用就好比这个保姆挨个询问每个孩子：你要尿尿吗？如果孩子回答是，保姆则把孩子拎出来放到另外一个地方。当所有孩子询问完之后，保姆领着这些要尿尿的孩子去上厕所（处理网络IO事件）。 还是以保姆照看一群孩子为例，在epoll机制下，保姆不再需要挨个的询问每个孩子是否需要尿尿。取而代之的是，每个孩子如果自己需要尿尿的时候，自己主动的站到事先约定好的地方，而保姆的职责就是查看事先约定好的地方是否有孩子。如果有小孩，则领着孩子去上厕所（网络事件处理）。因此，epoll的这种机制，能够高效的处理成千上万的并发连接，而且性能不会随着连接数增加而下降。

![](https://pic2.zhimg.com/v2-3c486898d786b26259c6abd6854794f5_b.jpg)

 select单个进程可监视的fd数量受到限制 epoll和select都可以实现同时监听多个I/O事件的状态 epoll基于轮训机制，select基于操作系统支持的I/O通知机制 epoll支持水平触发和边沿触发两种模式  


1 select

select本质上是通过设置或检查存放fd标志位的数据结构进行下一步处理。 这带来缺点： - 单个进程可监视的fd数量被限制，即能监听端口的数量有限 单个进程所能打开的最大连接数有`FD_SETSIZE`宏定义，其大小是32个整数的大小（在32位的机器上，大小就是3232，同理64位机器上FD\_SETSIZE为3264），当然我们可以对进行修改，然后重新编译内核，但是性能可能会受到影响，这需要进一步的测试 一般该数和系统内存关系很大，具体数目可以`cat /proc/sys/fs/file-max`察看。32位机默认1024个，64位默认2048。

![](../.gitbook/assets/image%20%28105%29.png)

* 对socket是线性扫描，即轮询，效率较低： 仅知道有I/O事件发生，却不知是哪几个流，只会无差异轮询所有流，找出能读数据或写数据的流进行操作。同时处理的流越多，无差别轮询时间越长 - O\(n\)。

当socket较多时，每次select都要通过遍历`FD_SETSIZE`个socket，不管是否活跃，这会浪费很多CPU时间。如果能给 socket 注册某个回调函数，当他们活跃时，自动完成相关操作，即可避免轮询，这就是**epoll**与**kqueue**。

调用过程

![](https://pic2.zhimg.com/v2-c6f11f735069b37a920907c14e3c5331_b.jpg)

 （1）使用copy\_from\_user从用户空间拷贝fd\_set到内核空间

（2）注册回调函数\_\_pollwait

（3）遍历所有fd，调用其对应的poll方法（对于socket，这个poll方法是sock\_poll，sock\_poll根据情况会调用到tcp\_poll,udp\_poll或者datagram\_poll）

（4）以tcp\_poll为例，其核心实现就是\_\_pollwait，也就是上面注册的回调函数。

（5）\_\_pollwait的主要工作就是把current（当前进程）挂到设备的等待队列中，不同的设备有不同的等待队列，对于tcp\_poll来说，其等待队列是sk-&gt;sk\_sleep（注意把进程挂到等待队列中并不代表进程已经睡眠了）。在设备收到一条消息（网络设备）或填写完文件数据（磁盘设备）后，会唤醒设备等待队列上睡眠的进程，这时current便被唤醒了。

（6）poll方法返回时会返回一个描述读写操作是否就绪的mask掩码，根据这个mask掩码给fd\_set赋值。

（7）如果遍历完所有的fd，还没有返回一个可读写的mask掩码，则会调用schedule\_timeout是调用select的进程（也就是current）进入睡眠。当设备驱动发生自身资源可读写后，会唤醒其等待队列上睡眠的进程。如果超过一定的超时时间（schedule\_timeout指定），还是没人唤醒，则调用select的进程会重新被唤醒获得CPU，进而重新遍历fd，判断有没有就绪的fd。

（8）把fd\_set从内核空间拷贝到用户空间。

缺点

内核需要将消息传递到用户空间，都需要内核拷贝动作。需要维护一个用来存放大量fd的数据结构，使得用户空间和内核空间在传递该结构时复制开销大。

* 每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大
* 同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大
  * select支持的文件描述符数量太小了，默认是1024

2 poll

poll的实现和select非常相似，只是描述fd集合的方式不同，poll使用pollfd结构而不是select的fd\_set结构，其他的都差不多,管理多个描述符也是进行轮询，根据描述符的状态进行处理，但是poll没有最大文件描述符数量的限制。poll和select同样存在一个缺点就是，包含大量文件描述符的数组被整体复制于用户态和内核的地址空间之间，而不论这些文件描述符是否就绪，它的开销随着文件描述符数量的增加而线性增大。

* 它将用户传入的数组拷贝到内核空间
* 然后查询每个fd对应的设备状态：
  * 如果设备就绪 在设备等待队列中加入一项继续遍历
  * 若遍历完所有fd后，都没发现就绪的设备 挂起当前进程，直到设备就绪或主动超时，被唤醒后它又再次遍历fd。这个过程经历多次无意义的遍历。

没有最大连接数限制，因其基于链表存储，其缺点： - 大量fd数组被整体复制于用户态和内核地址空间间，而不管是否有意义 - 如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd

3 epoll

可理解为**event poll**，epoll会把哪个流发生哪种I/O事件通知我们。所以epoll是事件驱动（每个事件关联fd）的，此时我们对这些流的操作都是有意义的。复杂度也降低到了O\(1\)。

3.1 触发模式

**EPOLLLT**和**EPOLLET**两种：

* LT，默认的模式（水平触发） 只要该fd还有数据可读，每次 `epoll_wait` 都会返回它的事件，提醒用户程序去操作，
* ET是“高速”模式（边缘触发）

![](https://pic2.zhimg.com/v2-310cc7857eabd42e324c109b5ca85b1d_b.png)

 只会提示一次，直到下次再有数据流入之前都不会再提示，无论fd中是否还有数据可读。所以在ET模式下，read一个fd的时候一定要把它的buffer读完，即读到read返回值小于请求值或遇到EAGAIN错误

epoll使用“事件”的就绪通知方式，通过`epoll_ctl`注册fd，一旦该fd就绪，内核就会采用类似回调机制激活该fd，`epoll_wait`便可收到通知。

#### EPOLLET触发模式的意义

若用`EPOLLLT`，系统中一旦有大量无需读写的就绪文件描述符，它们每次调用`epoll_wait`都会返回，这大大降低处理程序检索自己关心的就绪文件描述符的效率。 而采用`EPOLLET`，当被监控的文件描述符上有可读写事件发生时，`epoll_wait`会通知处理程序去读写。如果这次没有把数据全部读写完\(如读写缓冲区太小\)，那么下次调用`epoll_wait`时，它不会通知你，即只会通知你一次，直到该文件描述符上出现第二次可读写事件才会通知你。这比水平触发效率高，系统不会充斥大量你不关心的就绪文件描述符。

3.2 优点

* 没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）
* 效率提升，不是轮询，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数 即Epoll最大的优点就在于它只关心“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll
* 内存拷贝，利用mmap\(\)文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。
* epoll通过内核和用户空间共享一块内存来实现的

表面上看epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。

epoll跟select都能提供多路I/O复用的解决方案。在现在的Linux内核里有都能够支持，其中epoll是Linux所特有，而select则应该是POSIX所规定，一般操作系统均有实现。

select和poll都只提供了一个函数——select或者poll函数。而epoll提供了三个函数，epoll\_create,epoll\_ctl和epoll\_wait，epoll\_create是创建一个epoll句柄；epoll\_ctl是注册要监听的事件类型；epoll\_wait则是等待事件的产生。 - 对于第一个缺点，epoll的解决方案在epoll\_ctl函数中。每次注册新的事件到epoll句柄中时（在epoll\_ctl中指定EPOLL\_CTL\_ADD），会把所有的fd拷贝进内核，而不是在epoll\_wait的时候重复拷贝。epoll保证了每个fd在整个过程中只会拷贝一次。 - 对于第二个缺点，epoll的解决方案不像select或poll一样每次都把current轮流加入fd对应的设备等待队列中，而只在epoll\_ctl时把current挂一遍（这一遍必不可少）并为每个fd指定一个回调函数，当设备就绪，唤醒等待队列上的等待者时，就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪链表）。epoll\_wait的工作实际上就是在这个就绪链表中查看有没有就绪的fd（利用schedule\_timeout\(\)实现睡一会，判断一会的效果，和select实现中的第7步是类似的）。 - 对于第三个缺点，epoll没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。

4 总结

select，poll，epoll都是IO多路复用机制，即可以监视多个描述符，一旦某个描述符就绪（读或写就绪），能够通知程序进行相应读写操作。 但select，poll，epoll本质上都是**同步I/O**，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。

*  select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll\_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll\_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。 
*  select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll\_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也能节省不少的开销。

## 数据库SQL

### ★★☆ 手写 SQL 语句，特别是连接查询与分组查询。 

### ★★☆ 连接查询与子查询的比较。 



1.子查询  
1.1. MySQL从4.1版本开始支持子查询，使用子查询进行SELECT语句嵌套查询，可以一次完成很多逻辑上需要多个步骤才能完成的SQL操作  
1.2.子查询虽然很灵活，但是执行效率并不高  
1.3.执行子查询时，MYSQL需要创建临时表，查询完毕后再删除这些临时表，所以，子查询的速度会受到一定的影响，这里多了一个创建和销毁临时表的过程  
2.连接查询（join）  
2.1.可以使用连接查询（JOIN）代替子查询，连接查询不需要建立临时表，因此其速度比子查询快  
总结：连接查询效率高于子查询！！！  
扩展：多表联查性能优化  
**优化的本质就是\(join on 和where的执行顺序）！！！**  
1.数据库在通过连接两张或多张表来返回记录时，都会生成一张 中间的临时表，然后再将这张临时表返回给用户  
注意：这张临时表是数据库（MySQL自动生成）  
2.在使用left jion on时，on和where条件的区别如下：

2.1 on条件是在生成临时表时使用的条件，它不管on中的条件是否为真，都会返回左边表中的记录

2.2 where条件是在临时表生成好后，再对临时表进行过滤的条件（这时已经和left join没关系了），条件不为真的就全部过滤掉

3.left join on + where条件查询的索引优化实例分析：  
sql：select \* from A left join B on A.c = B.c where A.employee\_id = 3  
解读： A表left join B表，并且指定A表中的employee\_id为一个具体的值

3.1.假设A表，B表均有10000多条数据； 3.2.使用上面的sql查询时间达到16秒（在c字段不是任何索引，用explain分析得知，AB表都使用了全表查询，效率极低） 3.3.开始优化上面sql （1）给AB表列c都加索引（仅用了0.1s，但是分析后显示表A依然进行了全表扫描） 思考：为什么全表扫描的不是表B 因为Mysql内部的优化，使用小表驱动大表，它在估算到必须有一个表要全表扫描的话，一定会选择那个数据量更小的表去全表扫描， 也就是说，在这个查询中，因为on以后的where条件列并没有使用到索引，所以mysql的优化只用到了表B的c索引，没有用到表A的索引！ （2）我们有where条件查询，不需要全表扫描，此时就需要where条件生效，操作及分析如下： 1.将A表中的索引改为employee\_id+c（经验证两个所以都使用了，方案可行） 思考：sql执行 from中的on应该是优先于where语句的，为什么这里employee\_id反而在c之前，有违常理 因为Mysql内部优化，这一句Sql在执行的时候首先是选择了使用表B的索引来进行优化，将表A单独放出来进行后续的操作， 然后，又发现了where语句中A.employee\_id有一个聚合索引，并且employee\_id处于索引头，所以这个聚合索引是可用的，所以自然使用了此索引 2.即使把聚合索引后面的列c删掉，与使用聚合索引的效果是一样的，之前全表查询，现在根据条件只查询了满足条件的，时间大幅缩短

扩展：mysql连接查询中索引的重要性  
1.连接查询通过两张表中符合连接关系的字段来建立两张表的关联，通常包括内连接、左外连接、右外连接和全连接  
2.内连接会保留两张表中共有的那部分记录，因此最后产生的连接表记录数最少；  
全连接会保留两张表中所有的记录，因此最后产生的连接表记录数最多；  
左外连接会保留左表的全部记录，右外连接会保留右表的全部记录，因此最后产生的连接表记录数处于内连接和外连接之间。  
3.我们可以给关联表的字段添加索引来减少查询次数，提高查询效率  
**4.使用多表关联时，一般遵循以下规则：**  
4.1.左连接：一般给右边表的关联字段建立索引；  
4.2.右关联：一般给左边表的关联字段建立索引；  
4.3.内连接：一般给关联表的任意一边的关联字段建立索引即可

举例：学生表student（id，name），课程表class\(id,student\_id,class\),各有10000条数据 sql实例：SELECT a.id, name FROM student a LEFT JOIN class b ON a.id = b.student\_id 这个查询的执行速度非常慢！！ 1.首先用explain查看这个语句的查询执行计划，可以看到type都为ALL，即在student表和class表中都使用的全表扫描 2.改进：试着给class表的student\_id字段添加索引 alter table class add index class\_index\(student\_id\) 3.然后再次执行查询，发现速度非常快,这就是效率改进的关键点所在 4.当连接查询时产生的连接表过大时，为了防止查询次数过多，我们要经常使用索引来减少查询次数，提高查询效率

### ★★☆ drop、delete、truncate 比较。 

1. 作用

DELETE 删除表中 WHERE 语句指定的数据。

![](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/other20190427172519.png)

TRUNCATE 清空表，相当于删除表中的所有数据。

![](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/other20190427172344.png)

DROP 删除表结构。

![](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/other20190427172441.png)

2. 事务

* DELETE 会被放到日志中以便进行回滚；
* TRUNCATE 和 DROP 立即生效，不会放到日志中，也就不支持回滚。

3. 删除空间

* DELETE 不会减少表和索引占用的空间；
* TRUNCATE 会将表和索引占用的空间恢复到初始值；
* DROP 会将表和索引占用的空间释放。

4. 耗时

通常来说，DELETE &lt; TRUNCATE &lt; DROP。

### ★★☆ 视图的作用，以及何时能更新视图。 



1. 是什么

视图是虚拟的表，本身不包含数据，数据都存储在原始表中。

2. 创建视图

```text
CREATE VIEW myview AS
SELECT C1, Concat(C2, C3)
FROM mytable
WHERE C1 <= 2;
```

![](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/other20190427171937.png)

3. 有什么用

* 简化复杂的查询，比如复杂的连接查询；
* 只使用实际表的一部分数据；
* 通过只给用户访问视图的权限，保证数据的安全性；
* 更改数据格式和表示。

4. 何时可以更新

因为视图不存储数据，所以更新视图需要去更新原始表。如果视图定义只依赖于一个原始表，就很容易进行更新操作。但如果视图定义中有以下操作，那么就不能进行视图的更新：

* 分组查询
* 连接查询
* 子查询
* Union
* 聚集函数
* DISTINCT
* 计算字段

### ★☆☆ 理解存储过程、触发器等作用。系统原理

### ★★★ ACID 的作用以及实现原理。 

* 数据库事务：构成单一逻辑工作单元的操作集合
  * 数据库事务可以包含一个或多个数据库操作，但这些操作构成一个逻辑上的整体
  * 构成逻辑整体的这些数据库操作，要么全部执行成功，要么全部不执行
  * 构成事务的所有操作，要么全都对数据库产生影响，要么全都不产生影响，即不管事务是否执行成功，数据库总能保持一致性状态
  * 以上即使在数据库出现故障以及并发事务存在的情况下依然成立
* 事务的ACID特性
  * 原子性：事务中的所有操作作为一个整体像原子一样不可分割，要么全部成功，要么全部失败。
  * 原子性实现原理：

![](../.gitbook/assets/image%20%28107%29.png)

* 一致性：事务开始前和结束后，数据库的完整性约束没有被破坏，都是合法的数据状态。比如A向B转账，不可能A扣了钱，B却没收到。

![](../.gitbook/assets/image%20%28106%29.png)

* 隔离性：并发执行的事务不会相互影响，其对数据库的影响和它们串行执行时一样。 

![](../.gitbook/assets/image%20%28115%29.png)

![](../.gitbook/assets/image%20%28109%29.png)

* 持久性：事务一旦提交，其对数据库的更新就是持久的。任何事务或系统故障都不会导致数据丢失。

![](../.gitbook/assets/image%20%28113%29.png)

* 在事务的ACID特性中，一致性是事务的根本追求，而对数据库一致性的破坏主要来自两个方面：
  * 事务的并发执行
  * 事务故障或系统故障
* 如何避免数据库一致性被破坏
  * 并发控制技术：保证了事务的隔离性，使数据库的一致性不会因为并发执行被操作
  * 日志恢复技术：保证了事务的原子性，使数据库的一致性不会因事务或系统故障被破坏。同时使已提交的对数据库的修改不会因系统崩溃而丢失，保证了事务的持久性。 

![](../.gitbook/assets/image%20%28111%29.png)

### ★★★ 四大隔离级别，以及不可重复读和幻影读的出现原因。

* MySQL数据库事务隔离级别主要有四种：
  * `Serializable`：串行化，一个事务一个事务的执行。
  * `Repeatable read`：可重复读，无论其他事务是否修改并提交了数据，在这个事务中看到的数据值始终不受其他事务影响。
  * `Read committed`：读取已提交，其他事务提交了对数据的修改后，本事务就能读取到修改后的数据值。
  * `Read uncommitted`：读取未提交，其他事务只要修改了数据，即使未提交，本事务也能看到修改后的数据值。
  * MySQL数据库默认使用可重复读（ Repeatable read）。
* 使用乐观锁的时候，如果一个事务修改了库存并提交了事务，那其他的事务应该可以读取到修改后的数据值，所以不能使用可重复读的隔离级别，应该修改为读取已提交（Read committed）。

Read committed,读提交,读提交可以避免脏读,但可能出现幻读与不可重复读.

 ****Repeatable read比Read committed严格一点,是Mysql的默认级别,读取过程更多地受到MVCC影响,可防止不可重复读与脏读,但仍有可能出现幻读.

**脏读:**举个例子,如果你正在读数据库内容,而我现在修改了数据库内容还没有提交,接着我修改后的内容没有提交的情况下被你读到了,就叫脏读.

**不可重复读:**举个例子,比如你正在读数据库内容,而我update数据库后提交了,你又读了一次数据库内容,这时出现两个内容不同的结果,这叫不可重复读.

**幻读**:举个例子,比如你正在读数据库内容,而我insert数据库后提交了,你又读了一次数据库内容,这时你看到内容出现了多一条数据,这叫幻读.事务在插入事先检测不存在的记录时，惊奇的发现这些数据已经存在了，之前的检测读获取到的数据如同鬼影一般。

**脏读和不可重复读的区别是：**A 到底有没有提交信息

**脏读和不可重复读的相同点：** 都知道收到A 要转账给B 的意图

**不可重复读和幻想读的区别是**，不可重复读多次读的一个数据项，比如说多次只查询银行余额这个项（针对同一行数据的修改和删除用 update 和 delete），而幻想读是针对整个数据整体，比如银行员工查询今天交易的总人数，之前查的是100个人进行交易，进行第二次查询的时候，发现有105个人进行交易（主要是用insert 操作）。

**不可重复读和幻想读的相同之处是:** 多次查询期间，另一个人都递交了新的数据，导致前后读取的数据不一样。

### ★★☆ 封锁的类型以及粒度，两段锁协议，隐式和显示锁定。 

*   **3. 封锁**

  **3.1 封锁粒度**

  MySQL 中提供了两种封锁粒度：**行级锁以及表级锁**。

  * 应该尽量只锁定需要修改的那部分数据，而不是所有的资源。
  * 锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。
  * 但是加锁需要消耗资源，锁的各种操作（包括获取锁、释放锁、以及检查锁状态）都会增加系统开销。
  * 因此封锁粒度越小，系统开销就越大。

  在选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡。

  ![](https://img-blog.csdnimg.cn/20190426165842515.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1poeGluNjA2YQ==,size_16,color_FFFFFF,t_70)

  **3.2 封锁类型**

  **3.2.1 读写锁**

  * 排它锁（Exclusive） ，简写为 X 锁，又称写锁。
  * 共享锁（Shared） ，简写为 S 锁，又称读锁。

  有以下两个规定：

  一个事务对数据对象 A 加了 X 锁，就可以对 A 进行读取和更新。加锁期间其它事务不能对 A 加任何锁。

  一个事务对数据对象 A 加了 S 锁，可以对 A 进行读取操作，但是不能进行更新操作。加锁期间其它事务能对 A 加 S 锁，但是不能加 X 锁。

  锁的兼容关系如下：

  | - | X | S |
  | :--- | :--- | :--- |
  | X | × | × |
  | S | × | √ |

  **3.2.2 意向锁**

  使用意向锁（Intention Locks） 可以更容易地支持**多粒度封锁**。

  在存在行级锁和表级锁的情况下，事务 T 想要对表 A 加 X 锁，就需要先检测是否有其它事务对表 A 或者表 A 中的任意一行加了锁，那么就需要对表 A 的每一行都检测一次，这是非常耗时的。

  意向锁在原来的 X/S 锁之上引入了 IX/IS，IX/IS 都是表锁，用来表示一个事务想要在表中的某个数据行上加 X 锁或 S 锁。

  有以下两个规定：

  一个事务在获得某个数据行对象的 S 锁之前，必须先获得表的 IS 锁或者更强的锁；

  一个事务在获得某个数据行对象的 X 锁之前，必须先获得表的 IX 锁。

  通过引入意向锁，事务 T 想要对表 A 加 X 锁，只需要先检测是否有其它事务对表A 加了 X/IX/S/IS 锁，如果加了就表示有其它事务正在使用这个表或者表中某一行的锁，因此事务 T 加 X 锁失败。

  各种锁的兼容关系如下：

  | - | X | IX | S | IS |
  | :--- | :--- | :--- | :--- | :--- |
  | X | × | × | × | × |
  | IX | × | √ | × | √ |
  | S | × | × | √ | √ |
  | IS | × | √ | √ | √ |

  解释如下：

  任意 IS/IX 锁之间都是兼容的，因为它们只是表示想要对表加锁，而不是真正加锁；

  S 锁只与 S 锁和 IS 锁兼容，也就是说事务 T 想要对数据行加 S 锁，其它事务可以已经获得对表或者表中的行的 S 锁。

  **3.3 封锁协议**

  **3.3.1 三级封锁协议**

  **一级封锁协议**

  事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁。

  可以**解决丢失修改问题**，因为不能同时有两个事务对同一个数据进行修改，那么事务的修改就不会被覆盖。

  **二级封锁协议**

  在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁。

  可以**解决读脏数据问题**，因为如果一个事务在对数据 A 进行修改，根据 1 级封锁协议，会加 X 锁，那么就不能再加 S 锁了，也就是不会读入数据。

  **三级封锁协议**

  在二级的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S锁。

  可以**解决不可重复读的问题**，因为读 A 时，其它事务不能对 A 加 X 锁，从而避免了在读的期间数据发生改变。

  **3.3.2 两段锁协议**

  加锁和解锁分为两个阶段进行。

  **可串行化调度**是指，通过并发控制，使得并发执行的事务结果与某个串行执行的事务结果相同。

  事务遵循两段锁协议是**保证可串行化调度的充分条件**。

  例如以下操作满足两段锁协议，它是可串行化调度。

  ```text
  lock-x(A)...lock-s(B)...lock-s(C)...unlock(A)...unlock(C)...unlock(B)
  ```

  但不是必要条件，例如以下操作不满足两段锁协议，但是它还是可串行化调度

  ```text
  lock-x(A)...unlock(A)...lock-s(B)...unlock(B)...lock-s(C)...unlock(C)
  ```

  **3.4 MySQL 隐式与显示锁定**

  MySQL 的 InnoDB 存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定。

  InnoDB 也可以使用特定的语句进行显示锁定：

  ```text
  SELECT ... LOCK In SHARE MODE;SELECT ... FOR UPDATE;
  ```

### ★★★ 乐观锁与悲观锁。 

* 悲观锁
  * 当查询某条记录时，即让数据库为该记录加锁，锁住记录后别人无法操作，使用类似如下语法

    ```text
    select stock from tb_sku where id=1 for update;

    SKU.objects.select_for_update().get(id=1)
    ```

  * 悲观锁类似于我们在多线程资源竞争时添加的互斥锁，容易出现死锁现象，采用不多。
* 乐观锁
  * 乐观锁并不是真实存在的锁，而是在更新的时候判断此时的库存是否是之前查询出的库存，如果相同，表示没人修改，可以更新库存，否则表示别人抢过资源，不再执行库存更新。类似如下操作

    ```text
    update tb_sku set stock=2 where id=1 and stock=7;

    SKU.objects.filter(id=1, stock=7).update(stock=2)
    ```

### ★★★ MVCC 原理，当前读以及快照读，Next-Key Locks 解决幻影读。 

**事务的4个隔离级别**

* 读未提交
* 读已提交
* 可重复读
* 串行化

![](https://pic2.zhimg.com/v2-5bb4182e1ad66563f933180f4105b095_b.jpg)

* 什么是脏读

简单说，读了一条未提交的数据

* 什么是不可重复读？

一个事务读取了另外一个事务**修改**后记录 强调的是 update 和delete ,只需要锁住满足条件的记录即可

* 什么是幻读

一个事务读取了另外一个事务**插入**的数据，强调的是 insert ，要锁住满足条件及相近的记录。

MYSQL 中默认的隔离级别是可重复读，可解决脏读和不可重复读的问题。但是不能解决幻读的问题。 Oracle 默认的是Read Commit 读已提交，可以避免脏读的问题。

**MVCC 用来解决什么问题？**

一般解决不可重复读和幻读问题，是采用锁机制实现，有没有一种乐观锁的问题去处理，可以采用 MVCC 机制的设计，可以用来解决这个问题。取代行锁，降低系统开销。

**MVCC 是啥？**

MVCC 的英文全称是 Multiversion Concurrency Control ，中文意思是多版本并发控制技术。原理是，通过数据行的多个版本管理来实现数据库的并发控制，简单来说就是保存数据的历史版本。可以通过比较版本号决定数据是否显示出来。读取数据的时候不需要加锁可以保证事务的隔离效果。

**MVCC 可以解决什么问题？**

* 读写之间阻塞的问题，通过 MVCC 可以让读写互相不阻塞，读不相互阻塞，写不阻塞读，这样可以提升数据并发处理能力。
* 降低了死锁的概率，这个是因为 MVCC 采用了乐观锁的方式，读取数据时，不需要加锁，写操作，只需要锁定必要的行。
* 解决了一致性读的问题，当我们朝向某个数据库在时间点的快照是，只能看到这个时间点之前事务提交更新的结果，不能看到时间点之后事务提交的更新结果。

**什么是快照读？**

快照读，读取的是**快照数据**，不加锁的简单 Select 都属于快照读.

```text
SELECT * FROM player WHERE ...
```

**什么是当前读？**

当前读就是读的是**最新数据**,而不是历史的数据，加锁的 SELECT，或者对数据进行增删改都会进行当前读。

```text
SELECT * FROM player LOCK IN SHARE MODE;
SELECT FROM player FOR UPDATE;
INSERT INTO player values ...
DELETE FROM player WHERE ...
UPDATE player SET ...
```

**InnoDB 的 MVCC 是如何实现的？**

InnoDB 是如何存储记录多个版本的？这些数据是 事务版本号，行记录中的隐藏列和Undo Log。

#### **事务版本号**

每开启一个日志，都会从数据库中获得一个事务ID（也称为事务版本号），这个事务 ID 是自增的，通过 ID 大小，可以判断事务的时间顺序。

#### **行记录的隐藏列**

1. row\_id :隐藏的行 ID ,用来生成默认的聚集索引。如果创建数据表时没指定聚集索引，这时 InnoDB 就会用这个隐藏 ID 来创建聚集索引。采用聚集索引的方式可以提升数据的查找效率。
2. trx\_id: 操作这个数据事务 ID ，也就是最后一个对数据插入或者更新的事务 ID 。
3. roll\_ptr:回滚指针，指向这个记录的 Undo Log 信息。

![](https://pic4.zhimg.com/v2-6c8554423406f0e4481b9b8b0b800863_b.jpg)

#### **Undo Log**

InnoDB 将行记录快照保存在 Undo Log 里。![](https://pic4.zhimg.com/v2-dbf9e8c10cffbba915de717847512f4f_b.jpg)

数据行通过快照记录都通过链表的结构的串联了起来，每个快照都保存了 trx\_id 事务ID，如果要找到历史快照，就可以通过遍历回滚指针的方式进行查找。

**Read View 是啥？**

如果一个事务要查询行记录，需要读取哪个版本的行记录呢？ Read View 就是来解决这个问题的。Read View 可以帮助我们解决可见性问题。 Read View 保存了**当前事务开启时所有活跃的事务列表**。换个角度，可以理解为: **Read View 保存了不应该让这个事务看到的其他事务 ID 列表。**

1. trx\_ids 系统当前正在活跃的事务ID集合。
2. low\_limit\_id ,活跃事务的最大的事务 ID。
3. up\_limit\_id 活跃的事务中最小的事务 ID。
4. creator\_trx\_id，创建这个 ReadView 的事务ID。

**ReadView**

![](https://pic3.zhimg.com/v2-c22fd92467b2c69f626634e9a5dd0d8e_b.jpg)

如果当前事务的 creator\_trx\_id 想要读取某个行记录，这个行记录ID 的trx\_id ，这样会有以下的情况：

* 如果 trx\_id &lt; 活跃的最小事务ID（up\_limit\_id）,也就是说这个行记录在**这些活跃的事务创建前就已经提交了，那么这个行记录对当前事务是可见的。**
* 如果trx\_id &gt; 活跃的最大事务ID（low\_limit\_id），这个说明行记录在这些活跃的事务之后才创建，说明**这个行记录对当前事务是不可见的。**
* 如果 up\_limit\_id &lt; trx\_id &lt;low\_limit\_id,说明该记录需要在 trx\_ids 集合中，可能还处于活跃状态，因此我们需要在 trx\_ids 集合中遍历 ，如果trx\_id 存在于 trx\_ids 集合中，证明这个事务 trx\_id 还处于活跃状态，不可见，否则 ，trx\_id 不存在于 trx\_ids 集合中，说明事务trx\_id 已经提交了，这行记录是可见的。

**如何查询一条记录**

1. 获取事务自己的版本号，即 事务ID
2. 获取 Read View
3. 查询得到的数据，然后 Read View 中的事务版本号进行比较。
4. 如果不符合 ReadView 规则， 那么就需要 UndoLog 中历史快照；
5. 最后返回符合规则的数据

InnoDB 实现多版本控制 （MVCC）是通过 ReadView+ UndoLog 实现的，UndoLog 保存了历史快照，ReadView 规则帮助判断当前版本的数据是否可见。

**总结**

* 如果事务隔离级别是 ReadCommit ，一个事务的每一次 Select 都会去查一次ReadView ，每次查询的Read View 不同，就可能会造成不可重复读或者幻读的情况。
* 如果事务的隔离级别是可重读，为了避免不可重读读，一个事务只在第一次 Select 的时候会获取一次Read View ，然后后面索引的Select 会复用这个 ReadView.

**InnoDB有三种行锁的算法：**

1，Record Lock：单个行记录上的锁。

2，Gap Lock：间隙锁，锁定一个范围，但不包括记录本身。GAP锁的目的，是为了防止同一事务的两次当前读，出现幻读的情况。

3，Next-Key Lock：1+2，锁定一个范围，并且锁定记录本身。对于行的查询，都是采用该方法，主要目的是解决幻读的问题。  


### ★★☆ 范式理论。 

2.第一范式；是指数据库的每一列都是不可分割的基本数据项，同一列不能有多个值，即实体中的某个属性不能有多个值或者不能有重复的属性。

指导原则  
（1）数组的每个属性只能包含一个值  
（2）关系中的每个数组必须包含相同数量的值  
（3）关系中的每个数组一定不能相同

3.第二范式：如果一个数据表已经满足第一范式，而且该数据表中的任何一个非主键字段的数值都依赖于该数据表的主键字段，那么该数据表满足第二范式，即2NF

4.第三范式：如果一个数据表已经满足第二范式，而且该数据表中的任何两个非主键字段的数据值之间不存在函数依赖关系，那么该数据表满足第三范式，即3FN

### ★★★ SQL 与 NoSQL 的比较。



### 关于NoSQL和MySQL一点看法：

1. SQL和NoSQL有着相同的目标：存储数据。但是它们存储数据的方式不同，这可能会影响到你开发的项目，一种会简化你的开发，一种会阻碍你的开发。尽管目前NoSQL数据库非常的火爆，但是NoSQL是不能取代SQL的--它仅仅是SQL的一种替代品。
2. 一些项目可能会更适合使用SQL数据库，然而一些项目可能会比较适合使用NoSQL，有些项目使用哪一种都可以很好地达到预期的效果。
3. SQL和NoSQL没有明显的区别。一些SQL数据库也采用了NoSQL数据库的特性，反之亦然。在选择数据库方面的界限变得越来越模糊了，并且一些新的混合型数据库将会在不久的将来提供更多的选择。

### SQL和NoSQL的区别：

1. **SQL数据库提供关系型的表来存储数据，NoSQL数据库采用类JOSN的键值对来存储文档。**                                               SQL中的表结构具有严格的数据模式约束，因此存储数据很难出错。                                                                          NoSQL存储数据更加灵活自由，但是也会导致数据不一致性问题的发生。
2. **在SQL数据库中，除非你事先定义了表和字段的模式否则你无法向其中添加数据。在NoSQL数据库中，数据在任何时候都可以进行添加，不需要事先去定义文档和集合。**                                                                                                         SQL在进行数据的逻辑操作之前我们必须要定义数据模式，数据模式可以在后期进行更改，但是对于模式的大改将会是非常复杂的。因此NoSQL数据库更适合于那些不能够确定数据需求的的工程项目\(MongoDB会在集合中为每一个文档添加一个独一无二的id。如果你仍然想要定义索引，你也可以自己在之后定义\)。模式中包含了许多的信息：**主键** — 独一无二的标志就像ISBN唯一确定一条记录；**索引** — 通常设置索引字段加快搜索的速度**；关系** — 字段之间的逻辑连接**；计功能**例如触发器和存储程序  
3. **SQL具有数据库的规范化。NoSQL虽然可以同样使用规范化，但是更倾向非规范化。**                                                        在SQL中我们需要增加一张新表tableB，一张旧表tableB关联新表只需使用外键B\_id，用于引用tableB中的信息，这样的设计能够最小化数据的冗余，我们不需要为tableA重复的添加tableB的所有信息—只需要去引用就可以了。这项技术叫做数据库的规范化，具有实际的意义。我们可以更改tableB的信息而不用修改tableA中的数据。而NoSQL更多的是在tableA中为每项数据添加tableB的信息，这样会使查询更快，但是在更新出版社信息的记录变多时效率将会显著地下降。
4. **SQL具有JOIN操作。 NoSQL则没有**

   SQL语言为查询提供了强大的JOIN操作。我们可以使用单个SQL语句在多个表中获取相关数据。而在NoSQL中没有与JOIN相同的操作，对于具有SQL语言经验的人来说是非常令人震惊的。这也是非规范化存在的原因之一。

5. **SQL具有数据完整性。NoSQL则不具备数据完整性**

   大多数的数据库允许通过定义外键来进行数据库的完整性约束。在NoSQL数据库中则没有数据完整性的约束选项。你可以存储任何你想要存储的数据。理想情况下，单个文档将是项目的所有信息的唯一来源。

6. **SQL需要自定义事务。NoSQL 操作单个文档时具备事务性，而操作多个文档时则不具备事务性**

   在SQL数据库中，两条或者多条更新操作可以结合成一个事务（或者全部执行成功否则失败）执行。将两条更新操作绑定为一个事务确保了它们要么全部成功要么全部失败。在NoSQL数据库中，对于一个文档的更新操作是原子性的。换句话说，如果你要更新一个文档中的三个值，要么三个值都更新成功要么它们保持不变。然而，对于操作多个文档时没有与事务相对应的操作。在MongoDB中有一个操作是transaction-like options，但是，需要我们手动的加入到代码中。

7. **SQL使用SQL语言。NoSQL使用类JSON**

   SQL是一种声明性语言。SQL语言的功能强大，并且已经成为了一种国际的通用标准，尽管大多数系统在语法上有一些细微的差别。NoSQL数据库使用类似JOSN为参数的JavaScript来进行查询！基本操作是相同的，但是嵌套的JOSN将会产生复杂的查询。

8. **NoSQL比SQL更快**

   通常情况下，NoSQL比SQL语言更快。这并没有什么好震惊的，NoSQL中更加简单的非规范化存储允许我们在一次查询中得到特定项的所有信息。不需要使用SQL中复杂的JOIN操作。也就是说，你的项目的设计和数据的需求会有很大的影响。一个好的SQL数据库的设计的表现一定会比一个设计不好的NoSQL数据库性能好很多，反之亦然。

**适合使用SQL开发的项目：**                                                                                                                                         

1. 可以预先定义逻辑相关的离散数据的需求                                                                                                                     
2. 数据一致性是必要的                                                                                                                                                   
3. 具有良好的开发者经验和技术支持的标准的成熟技术

**适合使用NoSQL开发的项目：**                                                                                                                                    

1. 不相关，不确定和逐步发展的数据需求                                                                                                                        
2. 更简单或者更宽松的能够快速开始编程的项目
3. 速度和可扩展性至关重要的

## MySQL

### ★★★ B+ Tree 原理，与其它查找树的比较。 



### ★★★ MySQL 索引以及优化。 

### ★★★ 查询优化。 

### ★★★ InnoDB 与 MyISAM 比较。 

### ★★☆ 水平切分与垂直切分。 

### ★★☆ 主从复制原理、作用、实现。 

### ★☆☆ redo、undo、binlog 日志的作用。

## Redis

### ★★☆ 字典和跳跃表原理分析。 

### ★★★ 使用场景。 

### ★★★ 与 Memchached 的比较。 

### ★☆☆ 数据淘汰机制。 

### ★★☆ RDB 和 AOF 持久化机制。 

### ★★☆ 事件驱动模型。 

### ★☆☆ 主从复制原理。 

### ★★★ 集群与分布式。 

### ★★☆ 事务原理。 

### ★★★ 线程安全问题。

